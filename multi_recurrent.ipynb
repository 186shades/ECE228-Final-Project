{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables\n",
    "image_size = 256\n",
    "in_channel_spec = 9\n",
    "in_channel_tool = 3\n",
    "num_classes = 3\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 64\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DatasetCreator for combined spec and tool data\n",
    "class DatasetCreator(Dataset):\n",
    "    def __init__(self, spec_path, labels_path, image_size, channels):\n",
    "        # Read the Labels file as a dataframe and store the paths to specX,Y,Z and tool in the same dataframe.\n",
    "        # Don't load the images now, requires lot of memory.\n",
    "        # Load in __getitem__()\n",
    "        self.df = pd.read_csv(labels_path, index_col=0)\n",
    "        self.df['specX'] = self.df.index.map(lambda id: f'{spec_path}/specX/{id}.png')\n",
    "        self.df['specY'] = self.df.index.map(lambda id: f'{spec_path}/specY/{id}.png')\n",
    "        self.df['specZ'] = self.df.index.map(lambda id: f'{spec_path}/specZ/{id}.png')\n",
    "        self.df['tool'] = self.df.index.map(lambda id: f'{spec_path}/tool/{id}.jpg')\n",
    "        self.image_size = image_size\n",
    "        self.channels = channels\n",
    "\n",
    "    def __get_df__(self):\n",
    "        # Just for debugging purpose\n",
    "        return self.df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df.index)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # place holder for all the three images (each image has 3 channels)\n",
    "        image = torch.zeros((self.image_size, self.image_size, self.channels))\n",
    "\n",
    "        # idx_details has every think we need about the entry of that idx\n",
    "        idx_details = self.df.iloc[idx]\n",
    "\n",
    "        # Read images\n",
    "        # Note that we are not converting BGR to RGB because it doesn't matter to the NN\n",
    "        img_x = cv2.imread(idx_details['specX'])\n",
    "        res_x = cv2.resize(img_x, dsize=(image_size, image_size), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        img_y = cv2.imread(idx_details['specY'])\n",
    "        res_y = cv2.resize(img_y, dsize=(image_size, image_size), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        img_z = cv2.imread(idx_details['specZ'])\n",
    "        res_z = cv2.resize(img_z, dsize=(image_size, image_size), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        img_tool = cv2.imread(idx_details['tool'])\n",
    "        res_tool = cv2.resize(img_tool, dsize=(image_size, image_size), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        image = torch.cat((torch.tensor(res_x), torch.tensor(res_y), torch.tensor(res_z), torch.tensor(res_tool)), dim=2).float()\n",
    "\n",
    "        label = idx_details['tool_label']\n",
    "\n",
    "        # change image to CxHxW from HxWxC\n",
    "        return image.transpose(0, 2).transpose(1, 2), label -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./dataset_aug\"\n",
    "labels_path = \"./labels_aug/random_distribution\"\n",
    "\n",
    "train_dataset = DatasetCreator(data_path, os.path.join(labels_path, \"train.csv\"), image_size, 3)\n",
    "test_dataset = DatasetCreator(data_path, os.path.join(labels_path, \"test.csv\"), image_size, 3)\n",
    "val_dataset = DatasetCreator(data_path, os.path.join(labels_path, \"val.csv\"), image_size, 3)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2460 48 54\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset), len(test_dataset), len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 12, 256, 256]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "imgs, labels = next(iter(train_dataloader))\n",
    "print(imgs.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_label</th>\n",
       "      <th>tool_label</th>\n",
       "      <th>specX</th>\n",
       "      <th>specY</th>\n",
       "      <th>specZ</th>\n",
       "      <th>tool</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T6R1B4</th>\n",
       "      <td>sharp</td>\n",
       "      <td>1</td>\n",
       "      <td>./dataset_aug/specX/T6R1B4.png</td>\n",
       "      <td>./dataset_aug/specY/T6R1B4.png</td>\n",
       "      <td>./dataset_aug/specZ/T6R1B4.png</td>\n",
       "      <td>./dataset_aug/tool/T6R1B4.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T2R3B2</th>\n",
       "      <td>sharp</td>\n",
       "      <td>1</td>\n",
       "      <td>./dataset_aug/specX/T2R3B2.png</td>\n",
       "      <td>./dataset_aug/specY/T2R3B2.png</td>\n",
       "      <td>./dataset_aug/specZ/T2R3B2.png</td>\n",
       "      <td>./dataset_aug/tool/T2R3B2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T9R11B1</th>\n",
       "      <td>used</td>\n",
       "      <td>2</td>\n",
       "      <td>./dataset_aug/specX/T9R11B1.png</td>\n",
       "      <td>./dataset_aug/specY/T9R11B1.png</td>\n",
       "      <td>./dataset_aug/specZ/T9R11B1.png</td>\n",
       "      <td>./dataset_aug/tool/T9R11B1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T9R3B1</th>\n",
       "      <td>sharp</td>\n",
       "      <td>1</td>\n",
       "      <td>./dataset_aug/specX/T9R3B1.png</td>\n",
       "      <td>./dataset_aug/specY/T9R3B1.png</td>\n",
       "      <td>./dataset_aug/specZ/T9R3B1.png</td>\n",
       "      <td>./dataset_aug/tool/T9R3B1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T6R2B4</th>\n",
       "      <td>sharp</td>\n",
       "      <td>1</td>\n",
       "      <td>./dataset_aug/specX/T6R2B4.png</td>\n",
       "      <td>./dataset_aug/specY/T6R2B4.png</td>\n",
       "      <td>./dataset_aug/specZ/T6R2B4.png</td>\n",
       "      <td>./dataset_aug/tool/T6R2B4.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        image_label  tool_label                            specX  \\\n",
       "id                                                                 \n",
       "T6R1B4        sharp           1   ./dataset_aug/specX/T6R1B4.png   \n",
       "T2R3B2        sharp           1   ./dataset_aug/specX/T2R3B2.png   \n",
       "T9R11B1        used           2  ./dataset_aug/specX/T9R11B1.png   \n",
       "T9R3B1        sharp           1   ./dataset_aug/specX/T9R3B1.png   \n",
       "T6R2B4        sharp           1   ./dataset_aug/specX/T6R2B4.png   \n",
       "\n",
       "                                   specY                            specZ  \\\n",
       "id                                                                          \n",
       "T6R1B4    ./dataset_aug/specY/T6R1B4.png   ./dataset_aug/specZ/T6R1B4.png   \n",
       "T2R3B2    ./dataset_aug/specY/T2R3B2.png   ./dataset_aug/specZ/T2R3B2.png   \n",
       "T9R11B1  ./dataset_aug/specY/T9R11B1.png  ./dataset_aug/specZ/T9R11B1.png   \n",
       "T9R3B1    ./dataset_aug/specY/T9R3B1.png   ./dataset_aug/specZ/T9R3B1.png   \n",
       "T6R2B4    ./dataset_aug/specY/T6R2B4.png   ./dataset_aug/specZ/T6R2B4.png   \n",
       "\n",
       "                                   tool  \n",
       "id                                       \n",
       "T6R1B4    ./dataset_aug/tool/T6R1B4.jpg  \n",
       "T2R3B2    ./dataset_aug/tool/T2R3B2.jpg  \n",
       "T9R11B1  ./dataset_aug/tool/T9R11B1.jpg  \n",
       "T9R3B1    ./dataset_aug/tool/T9R3B1.jpg  \n",
       "T6R2B4    ./dataset_aug/tool/T6R2B4.jpg  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = train_dataset.__get_df__()\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: import model definition from other ipynb files\n",
    "\n",
    "kernel = (3,3)\n",
    "patch = 32\n",
    "filters = 128\n",
    "depth = 4\n",
    "padding = (1,1)\n",
    "\n",
    "class DepthWiseConvolutionBlock(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.dconv = nn.Conv2d(in_channels=filters, out_channels=filters, kernel_size=kernel, stride=1, padding=padding, groups=filters)\n",
    "        self.activation1 = nn.GELU()\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=filters)\n",
    "        self.pconv = nn.Conv2d(in_channels=filters, out_channels=filters, kernel_size=1)\n",
    "        self.activation2 = nn.GELU()\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=filters)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = x\n",
    "        _ = self.dconv(x)\n",
    "        _ = x0 + self.bn1(self.activation1(_))\n",
    "        _ = self.pconv(_)\n",
    "        return self.bn2(self.activation2(_))\n",
    "    \n",
    "class BaseBlock(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=in_channel_spec, out_channels=filters, stride=patch, kernel_size=patch, padding=0)\n",
    "        self.activation = nn.GELU()\n",
    "        self.bn = nn.BatchNorm2d(num_features=filters)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _ = self.conv(x)\n",
    "        _ = self.activation(_)\n",
    "        return self.bn(_)\n",
    "    \n",
    "# class ClassificationBlock(nn.Module):\n",
    "#     def __init__(self, *args, **kwargs) -> None:\n",
    "#         super().__init__(*args, **kwargs)\n",
    "\n",
    "#         self.pool = nn.AdaptiveAvgPool2d(output_size=(1,1))\n",
    "#         self.linear = nn.Linear(in_features=filters, out_features=num_classes)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # print(x.shape)\n",
    "#         _ = self.pool(x)\n",
    "#         # print(f\"After Avg Pooling: {_.shape}\")\n",
    "#         _ = _.view(x.shape[0], -1)\n",
    "#         return self.linear(_)\n",
    "    \n",
    "class SpectogramModel(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.model = None\n",
    "        layers = [BaseBlock()]\n",
    "        for i in range(depth):\n",
    "            layers.append(DepthWiseConvolutionBlock())\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        # CLassification\n",
    "        self.pool = nn.AdaptiveAvgPool2d(output_size=(1,1))\n",
    "        self.linear = nn.Linear(in_features=filters, out_features=num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        _ = self.model(x)\n",
    "        _ = self.pool(_)\n",
    "        _ = _.view(x.shape[0], -1)\n",
    "        return self.linear(_)\n",
    "    \n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=3, cnn_out_channels=64):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, cnn_out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(cnn_out_channels)\n",
    "        self.conv2 = nn.Conv2d(cnn_out_channels, cnn_out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(cnn_out_channels)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(cnn_out_channels * (image_size // 4) ** 2, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Tool Parameters:\n",
      "conv1.weight: requires_grad=False\n",
      "conv1.bias: requires_grad=False\n",
      "bn1.weight: requires_grad=False\n",
      "bn1.bias: requires_grad=False\n",
      "conv2.weight: requires_grad=False\n",
      "conv2.bias: requires_grad=False\n",
      "bn2.weight: requires_grad=False\n",
      "bn2.bias: requires_grad=False\n",
      "fc1.weight: requires_grad=False\n",
      "fc1.bias: requires_grad=False\n",
      "fc2.weight: requires_grad=False\n",
      "fc2.bias: requires_grad=False\n",
      "\n",
      "Model Spec Parameters:\n",
      "model.0.conv.weight: requires_grad=False\n",
      "model.0.conv.bias: requires_grad=False\n",
      "model.0.bn.weight: requires_grad=False\n",
      "model.0.bn.bias: requires_grad=False\n",
      "model.1.dconv.weight: requires_grad=False\n",
      "model.1.dconv.bias: requires_grad=False\n",
      "model.1.bn1.weight: requires_grad=False\n",
      "model.1.bn1.bias: requires_grad=False\n",
      "model.1.pconv.weight: requires_grad=False\n",
      "model.1.pconv.bias: requires_grad=False\n",
      "model.1.bn2.weight: requires_grad=False\n",
      "model.1.bn2.bias: requires_grad=False\n",
      "model.2.dconv.weight: requires_grad=False\n",
      "model.2.dconv.bias: requires_grad=False\n",
      "model.2.bn1.weight: requires_grad=False\n",
      "model.2.bn1.bias: requires_grad=False\n",
      "model.2.pconv.weight: requires_grad=False\n",
      "model.2.pconv.bias: requires_grad=False\n",
      "model.2.bn2.weight: requires_grad=False\n",
      "model.2.bn2.bias: requires_grad=False\n",
      "model.3.dconv.weight: requires_grad=False\n",
      "model.3.dconv.bias: requires_grad=False\n",
      "model.3.bn1.weight: requires_grad=False\n",
      "model.3.bn1.bias: requires_grad=False\n",
      "model.3.pconv.weight: requires_grad=False\n",
      "model.3.pconv.bias: requires_grad=False\n",
      "model.3.bn2.weight: requires_grad=False\n",
      "model.3.bn2.bias: requires_grad=False\n",
      "model.4.dconv.weight: requires_grad=False\n",
      "model.4.dconv.bias: requires_grad=False\n",
      "model.4.bn1.weight: requires_grad=False\n",
      "model.4.bn1.bias: requires_grad=False\n",
      "model.4.pconv.weight: requires_grad=False\n",
      "model.4.pconv.bias: requires_grad=False\n",
      "model.4.bn2.weight: requires_grad=False\n",
      "model.4.bn2.bias: requires_grad=False\n",
      "linear.weight: requires_grad=False\n",
      "linear.bias: requires_grad=False\n"
     ]
    }
   ],
   "source": [
    "# Path to the models\n",
    "model_path = 'models'\n",
    "\n",
    "# Load the models\n",
    "model_spec = SpectogramModel()\n",
    "model_spec.load_state_dict(torch.load(f\"{model_path}/model_d4.pth\"))\n",
    "model_spec = model_spec.to(device)\n",
    "\n",
    "model_tool = SimpleCNN()\n",
    "model_tool.load_state_dict(torch.load(f\"{model_path}/tool_model.pth\"))\n",
    "model_tool = model_tool.to(device)\n",
    "\n",
    "# Freeze the models\n",
    "for param in model_spec.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model_tool.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Verify that the parameters are frozen\n",
    "print(\"Model Tool Parameters:\")\n",
    "for name, param in model_tool.named_parameters():\n",
    "    print(f\"{name}: requires_grad={param.requires_grad}\")\n",
    "\n",
    "print(\"\\nModel Spec Parameters:\")\n",
    "for name, param in model_spec.named_parameters():\n",
    "    print(f\"{name}: requires_grad={param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpectogramModel(\n",
       "  (model): Sequential(\n",
       "    (0): BaseBlock(\n",
       "      (conv): Conv2d(9, 128, kernel_size=(32, 32), stride=(32, 32))\n",
       "      (activation): GELU(approximate='none')\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): DepthWiseConvolutionBlock(\n",
       "      (dconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "      (activation1): GELU(approximate='none')\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (pconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (activation2): GELU(approximate='none')\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): DepthWiseConvolutionBlock(\n",
       "      (dconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "      (activation1): GELU(approximate='none')\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (pconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (activation2): GELU(approximate='none')\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): DepthWiseConvolutionBlock(\n",
       "      (dconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "      (activation1): GELU(approximate='none')\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (pconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (activation2): GELU(approximate='none')\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): DepthWiseConvolutionBlock(\n",
       "      (dconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "      (activation1): GELU(approximate='none')\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (pconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (activation2): GELU(approximate='none')\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (linear): Linear(in_features=128, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1079, device='cuda:0')\n",
      "tensor([1, 0, 1, 1, 2, 2, 0, 0, 1, 2, 2, 2, 2, 2, 0, 2, 1, 2, 1, 0, 0, 1, 1, 2,\n",
      "        2, 2, 0, 1, 2, 2, 1, 1, 0, 2, 0, 2, 0, 2, 1, 2, 0, 1, 1, 2, 0, 1, 1, 2,\n",
      "        0, 2, 0, 1, 2, 1, 1, 0, 0, 1, 0, 1, 2, 1, 0, 1], device='cuda:0') tensor([[ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489],\n",
      "        [ 0.0318,  0.1604, -0.1489]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Sanity Test Spec Model\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "x = torch.zeros((64, 9, 256, 256)).to(device)\n",
    "y = torch.randint(0, 3, (64, )).to(device)\n",
    "y_pred = model_spec(x)\n",
    "loss = loss_func(y_pred, y)\n",
    "# loss.backward() # comented since model weights are frozen, uncommenting should give error\n",
    "\n",
    "print(loss)\n",
    "print(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=262144, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1498, device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') tensor([[ 3.1653,  1.1233, -0.9634],\n",
      "        [ 3.5217,  1.1784, -1.0462],\n",
      "        [ 3.1210,  1.0362, -0.8305],\n",
      "        [ 2.4183,  0.9249, -0.6793],\n",
      "        [ 2.8012,  1.4006, -1.2274],\n",
      "        [ 2.9382,  0.8488, -0.6963],\n",
      "        [ 3.0744,  1.0800, -0.9233],\n",
      "        [ 3.1113,  0.7690, -0.6199],\n",
      "        [ 2.7083,  1.2172, -1.0807],\n",
      "        [ 3.1402,  1.0760, -0.9172],\n",
      "        [ 2.9381,  1.0565, -0.9146],\n",
      "        [ 2.8738,  1.0775, -0.9073],\n",
      "        [ 3.0264,  1.0947, -0.9747],\n",
      "        [ 3.1752,  1.0499, -0.8571],\n",
      "        [ 3.2311,  0.6781, -0.5510],\n",
      "        [ 3.5312,  1.1444, -1.0046],\n",
      "        [ 3.0633,  0.7790, -0.6426],\n",
      "        [ 3.1425,  0.7531, -0.5978],\n",
      "        [ 3.0175,  1.3468, -1.1257],\n",
      "        [ 2.9297,  1.0591, -0.9642],\n",
      "        [ 2.9426,  0.9587, -0.8060],\n",
      "        [ 3.2006,  0.9918, -0.8087],\n",
      "        [ 3.0525,  1.1145, -0.9905],\n",
      "        [ 3.3348,  0.7755, -0.6473],\n",
      "        [ 2.6292,  0.9571, -0.8170],\n",
      "        [ 3.0377,  0.9347, -0.8180],\n",
      "        [ 3.2549,  0.6665, -0.4941],\n",
      "        [ 3.2485,  0.9743, -0.8133],\n",
      "        [ 3.3609,  1.1880, -1.0348],\n",
      "        [ 3.2317,  1.1151, -0.9530],\n",
      "        [ 2.6817,  0.7714, -0.6233],\n",
      "        [ 3.2557,  1.0853, -0.9780],\n",
      "        [ 3.0821,  0.8018, -0.6731],\n",
      "        [ 3.0050,  0.9924, -0.8121],\n",
      "        [ 2.7272,  0.8713, -0.7138],\n",
      "        [ 2.7649,  1.0075, -0.8205],\n",
      "        [ 3.0694,  1.0406, -0.8677],\n",
      "        [ 3.1376,  0.9332, -0.7865],\n",
      "        [ 2.7267,  0.9685, -0.8467],\n",
      "        [ 3.2080,  1.1751, -1.0449],\n",
      "        [ 3.1505,  1.0759, -0.9481],\n",
      "        [ 3.0390,  0.8851, -0.7766],\n",
      "        [ 2.7138,  1.1645, -0.9867],\n",
      "        [ 2.7332,  0.9691, -0.8024],\n",
      "        [ 2.7000,  0.9406, -0.7962],\n",
      "        [ 2.7696,  0.9033, -0.7674],\n",
      "        [ 2.9988,  0.6514, -0.5621],\n",
      "        [ 2.6466,  1.0682, -0.9789],\n",
      "        [ 3.4957,  0.9803, -0.8317],\n",
      "        [ 3.2561,  0.7053, -0.5192],\n",
      "        [ 3.0610,  1.1200, -0.9511],\n",
      "        [ 3.0598,  0.9769, -0.8350],\n",
      "        [ 3.2867,  0.6849, -0.5707],\n",
      "        [ 2.9847,  0.9390, -0.8138],\n",
      "        [ 3.1129,  1.1232, -1.0025],\n",
      "        [ 2.9029,  0.9652, -0.8301],\n",
      "        [ 3.4492,  0.8944, -0.7219],\n",
      "        [ 2.7701,  0.9222, -0.7573],\n",
      "        [ 3.2106,  1.1018, -0.9536],\n",
      "        [ 3.0362,  0.9114, -0.7228],\n",
      "        [ 2.2272,  0.9555, -0.4790],\n",
      "        [ 2.5267,  0.9602, -0.7563],\n",
      "        [ 2.4980,  0.9151, -0.7335],\n",
      "        [ 2.6901,  1.1959, -1.0226]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Sanity Test Tool Model\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "x = torch.zeros((64, 3, 256, 256)).to(device)\n",
    "y = torch.randint(0, 1, (64, )).to(device)\n",
    "y_pred = model_tool(x)\n",
    "loss = loss_func(y_pred, y)\n",
    "# loss.backward() # comented since model weights are frozen, uncommenting should give error\n",
    "\n",
    "print(loss)\n",
    "print(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi Modal Model Definition\n",
    "class MultimodalConvModel(nn.Module):\n",
    "    def __init__(self, model_tool, model_spec, num_classes):\n",
    "        super(MultimodalConvModel, self).__init__()\n",
    "\n",
    "        # Truncate the tool model\n",
    "        self.truncated_model_tool = nn.Sequential(*list(model_tool.children())[:-3]).to(device)\n",
    "\n",
    "        # truncate the spec model\n",
    "        # self.truncated_model_spec = nn.Sequential(*list(*list(model_spec.children()))[:-1]).to(device)\n",
    "\n",
    "        self.truncated_model_spec = nn.Sequential(*list(model_spec.children())[:-1]).to(device)\n",
    "\n",
    "        # TODO: get flattened models with correct output shapes from both models directly, instead of this hack\n",
    "        self.pool = nn.AdaptiveAvgPool2d(output_size=(1,1))\n",
    "\n",
    "        print(self.truncated_model_tool)\n",
    "        print(self.truncated_model_spec)\n",
    "\n",
    "        # Verify that the parameters are frozen\n",
    "        print(\"Model Tool Parameters:\")\n",
    "        for name, param in self.truncated_model_tool.named_parameters():\n",
    "            print(f\"{name}: requires_grad={param.requires_grad}\")\n",
    "\n",
    "        print(\"\\nModel Spec Parameters:\")\n",
    "        for name, param in self.truncated_model_spec.named_parameters():\n",
    "            print(f\"{name}: requires_grad={param.requires_grad}\")\n",
    "       \n",
    "\n",
    "        # Get the input shapes of the models\n",
    "        tool_input_shape = list(model_tool.children())[0].weight.shape\n",
    "        print(tool_input_shape)\n",
    "\n",
    "        spec_input_shape = list(list(model_spec.children())[0][0].children())[0].weight.shape\n",
    "        print(spec_input_shape)\n",
    "\n",
    "        # Get the output shapes of the models\n",
    "        tool_output_dim = self.truncated_model_tool(torch.zeros(*tool_input_shape).to(device)).shape[1]\n",
    "        print(tool_output_dim)\n",
    "\n",
    "        spec_output_dim = self.truncated_model_spec(torch.zeros(*spec_input_shape).to(device)).shape[1]\n",
    "        print(spec_output_dim)\n",
    "\n",
    "        # GRU and classification layer\n",
    "        self.gru = nn.GRU(tool_output_dim + spec_output_dim, 256, dropout=0.1, batch_first=True)\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        tool_output = self.truncated_model_tool(x2)\n",
    "        spec_output = self.truncated_model_spec(x1)\n",
    "        # spec_output = self.pool(spec_output)\n",
    "        tool_output = self.pool(tool_output)\n",
    "        # print(tool_output.shape)\n",
    "        # print(spec_output.shape)\n",
    "        merged_output = torch.cat([tool_output, spec_output], dim=1)\n",
    "        # print(merged_output.shape)\n",
    "        merged_output = merged_output.view(merged_output.size(0), merged_output.size(1))\n",
    "        # print(merged_output.shape)\n",
    "        gru_output, _ = self.gru(merged_output)\n",
    "        output = self.fc(gru_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): BaseBlock(\n",
      "      (conv): Conv2d(9, 128, kernel_size=(32, 32), stride=(32, 32))\n",
      "      (activation): GELU(approximate='none')\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): DepthWiseConvolutionBlock(\n",
      "      (dconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "      (activation1): GELU(approximate='none')\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (pconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (activation2): GELU(approximate='none')\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): DepthWiseConvolutionBlock(\n",
      "      (dconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "      (activation1): GELU(approximate='none')\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (pconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (activation2): GELU(approximate='none')\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): DepthWiseConvolutionBlock(\n",
      "      (dconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "      (activation1): GELU(approximate='none')\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (pconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (activation2): GELU(approximate='none')\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): DepthWiseConvolutionBlock(\n",
      "      (dconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "      (activation1): GELU(approximate='none')\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (pconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (activation2): GELU(approximate='none')\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      ")\n",
      "Model Tool Parameters:\n",
      "0.weight: requires_grad=False\n",
      "0.bias: requires_grad=False\n",
      "1.weight: requires_grad=False\n",
      "1.bias: requires_grad=False\n",
      "2.weight: requires_grad=False\n",
      "2.bias: requires_grad=False\n",
      "3.weight: requires_grad=False\n",
      "3.bias: requires_grad=False\n",
      "\n",
      "Model Spec Parameters:\n",
      "0.0.conv.weight: requires_grad=False\n",
      "0.0.conv.bias: requires_grad=False\n",
      "0.0.bn.weight: requires_grad=False\n",
      "0.0.bn.bias: requires_grad=False\n",
      "0.1.dconv.weight: requires_grad=False\n",
      "0.1.dconv.bias: requires_grad=False\n",
      "0.1.bn1.weight: requires_grad=False\n",
      "0.1.bn1.bias: requires_grad=False\n",
      "0.1.pconv.weight: requires_grad=False\n",
      "0.1.pconv.bias: requires_grad=False\n",
      "0.1.bn2.weight: requires_grad=False\n",
      "0.1.bn2.bias: requires_grad=False\n",
      "0.2.dconv.weight: requires_grad=False\n",
      "0.2.dconv.bias: requires_grad=False\n",
      "0.2.bn1.weight: requires_grad=False\n",
      "0.2.bn1.bias: requires_grad=False\n",
      "0.2.pconv.weight: requires_grad=False\n",
      "0.2.pconv.bias: requires_grad=False\n",
      "0.2.bn2.weight: requires_grad=False\n",
      "0.2.bn2.bias: requires_grad=False\n",
      "0.3.dconv.weight: requires_grad=False\n",
      "0.3.dconv.bias: requires_grad=False\n",
      "0.3.bn1.weight: requires_grad=False\n",
      "0.3.bn1.bias: requires_grad=False\n",
      "0.3.pconv.weight: requires_grad=False\n",
      "0.3.pconv.bias: requires_grad=False\n",
      "0.3.bn2.weight: requires_grad=False\n",
      "0.3.bn2.bias: requires_grad=False\n",
      "0.4.dconv.weight: requires_grad=False\n",
      "0.4.dconv.bias: requires_grad=False\n",
      "0.4.bn1.weight: requires_grad=False\n",
      "0.4.bn1.bias: requires_grad=False\n",
      "0.4.pconv.weight: requires_grad=False\n",
      "0.4.pconv.bias: requires_grad=False\n",
      "0.4.bn2.weight: requires_grad=False\n",
      "0.4.bn2.bias: requires_grad=False\n",
      "torch.Size([64, 3, 3, 3])\n",
      "torch.Size([128, 9, 32, 32])\n",
      "64\n",
      "128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "#init model, loss function, optimizer\n",
    "model = MultimodalConvModel(model_tool, model_spec, num_classes).to(device)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultimodalConvModel(\n",
       "  (truncated_model_tool): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (truncated_model_spec): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): BaseBlock(\n",
       "        (conv): Conv2d(9, 128, kernel_size=(32, 32), stride=(32, 32))\n",
       "        (activation): GELU(approximate='none')\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): DepthWiseConvolutionBlock(\n",
       "        (dconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "        (activation1): GELU(approximate='none')\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (pconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation2): GELU(approximate='none')\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): DepthWiseConvolutionBlock(\n",
       "        (dconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "        (activation1): GELU(approximate='none')\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (pconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation2): GELU(approximate='none')\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): DepthWiseConvolutionBlock(\n",
       "        (dconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "        (activation1): GELU(approximate='none')\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (pconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation2): GELU(approximate='none')\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): DepthWiseConvolutionBlock(\n",
       "        (dconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "        (activation1): GELU(approximate='none')\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (pconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation2): GELU(approximate='none')\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (gru): GRU(192, 256, batch_first=True, dropout=0.1)\n",
       "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and eval functions\n",
    "def train(model, dataloader, optimizer, loss_func, device):\n",
    "    model.train()\n",
    "    model = model.to(device)\n",
    "    total_loss, total_count, acc_count = 0, 0, 0\n",
    "\n",
    "    for idx, (X, y) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # print(X.shape)\n",
    "        # print(y.shape)\n",
    "\n",
    "        # Split X into input_tool and input_spec\n",
    "        input_spec = X[:, :in_channel_spec, ...]\n",
    "        input_tool = X[:, in_channel_spec:in_channel_spec + in_channel_tool, ...]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(input_spec, input_tool)\n",
    "        loss = loss_func(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Loss\n",
    "        total_loss += loss.item()\n",
    "        total_count += X.size(0) # Batch size\n",
    "\n",
    "        # Accuracy\n",
    "        _, y_pred_class = y_pred.max(dim=1)\n",
    "        acc_count += (y_pred_class == y).sum().item()\n",
    "\n",
    "    return total_loss/total_count, acc_count/total_count\n",
    "\n",
    "def evaluate(model, dataloader, loss_func, device):\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    total_loss, total_count, acc_count = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (X, y) in enumerate(dataloader):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # Split X into input_tool and input_spec\n",
    "            input_spec = X[:, :in_channel_spec, ...]\n",
    "            input_tool = X[:, in_channel_spec:in_channel_spec + in_channel_tool, ...]\n",
    "\n",
    "            y_pred = model(input_spec, input_tool)\n",
    "            loss = loss_func(y_pred, y)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_count += X.size(0)\n",
    "\n",
    "            # Accuracy\n",
    "            _, y_pred_class = y_pred.max(dim=1)\n",
    "            acc_count += (y_pred_class == y).sum().item()\n",
    "\n",
    "    return total_loss/total_count, acc_count/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started new epoch ..\n",
      "======================================================================================================\n",
      "| Epoch 1/10 | time: 126.968 | Train Loss: 0.003 | Val Loss: 0.004 | Train Acc: 0.944 | Val Acc: 0.907 |\n",
      "started new epoch ..\n",
      "======================================================================================================\n",
      "| Epoch 2/10 | time: 112.207 | Train Loss: 0.001 | Val Loss: 0.005 | Train Acc: 0.980 | Val Acc: 0.944 |\n",
      "started new epoch ..\n",
      "======================================================================================================\n",
      "| Epoch 3/10 | time: 116.302 | Train Loss: 0.001 | Val Loss: 0.004 | Train Acc: 0.986 | Val Acc: 0.926 |\n",
      "started new epoch ..\n",
      "======================================================================================================\n",
      "| Epoch 4/10 | time: 114.798 | Train Loss: 0.000 | Val Loss: 0.004 | Train Acc: 0.993 | Val Acc: 0.926 |\n",
      "started new epoch ..\n",
      "======================================================================================================\n",
      "| Epoch 5/10 | time: 116.895 | Train Loss: 0.000 | Val Loss: 0.004 | Train Acc: 0.997 | Val Acc: 0.926 |\n",
      "started new epoch ..\n",
      "======================================================================================================\n",
      "| Epoch 6/10 | time: 128.697 | Train Loss: 0.000 | Val Loss: 0.004 | Train Acc: 1.000 | Val Acc: 0.926 |\n",
      "started new epoch ..\n",
      "======================================================================================================\n",
      "| Epoch 7/10 | time: 118.361 | Train Loss: 0.000 | Val Loss: 0.004 | Train Acc: 1.000 | Val Acc: 0.926 |\n",
      "started new epoch ..\n",
      "======================================================================================================\n",
      "| Epoch 8/10 | time: 167.338 | Train Loss: 0.000 | Val Loss: 0.004 | Train Acc: 1.000 | Val Acc: 0.926 |\n",
      "started new epoch ..\n",
      "======================================================================================================\n",
      "| Epoch 9/10 | time: 117.313 | Train Loss: 0.000 | Val Loss: 0.004 | Train Acc: 1.000 | Val Acc: 0.926 |\n",
      "started new epoch ..\n",
      "======================================================================================================\n",
      "| Epoch 10/10 | time: 896.319 | Train Loss: 0.000 | Val Loss: 0.004 | Train Acc: 1.000 | Val Acc: 0.926 |\n"
     ]
    }
   ],
   "source": [
    "#training loop\n",
    "train_loss_epochs = []\n",
    "val_loss_epochs = []\n",
    "train_acc_epochs = []\n",
    "val_acc_epochs = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start = time.time()\n",
    "    print(\"started new epoch ..\")\n",
    "    loss_train, train_acc = train(model, train_dataloader, optimizer, loss_func, device)\n",
    "    loss_val, val_acc = evaluate(model, val_dataloader, loss_func, device)\n",
    "\n",
    "    train_loss_epochs.append(loss_train)\n",
    "    val_loss_epochs.append(loss_val)\n",
    "    train_acc_epochs.append(train_acc)\n",
    "    val_acc_epochs.append(val_acc)\n",
    "    end = time.time()\n",
    "\n",
    "    print(\"=\" * 102)\n",
    "    print(f\"| Epoch {epoch+1}/{num_epochs} | time: {(end-start):.3f} | Train Loss: {loss_train:.3f} | Val Loss: {loss_val:.3f} | Train Acc: {train_acc:.3f} | Val Acc: {val_acc:.3f} |\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.9791666666666666\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model, test_dataloader, loss_func, device)\n",
    "print(\"Test Accuracy: \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save loss and accuracy\n",
    "torch.save(model.state_dict(), \"models/rnn_model\")\n",
    "torch.save(train_loss_epochs, \"output/train_loss_epochs.pt\")\n",
    "torch.save(val_loss_epochs, \"output/val_loss_epochs.pt\")\n",
    "torch.save(train_acc_epochs, \"output/train_acc_epochs.pt\")\n",
    "torch.save(val_acc_epochs, \"output/val_acc_epochs.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot Epoch vs. Loss\n",
    "plt.plot(train_loss_epochs, label=\"Train\")\n",
    "plt.plot(val_loss_epochs, label=\"Validation\")\n",
    "plt.title(\"Epoch vs Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "#plot Epoch vs. Accuracy\n",
    "plt.plot(train_acc_epochs, label=\"Train\")\n",
    "plt.plot(val_acc_epochs, label=\"Validation\")\n",
    "plt.title(\"Epoch vs Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

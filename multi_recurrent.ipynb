{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables\n",
    "image_size = 256\n",
    "in_channel_spec = 9\n",
    "in_channel_tool = 3\n",
    "num_classes = 3\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 64\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DatasetCreator for combined spec and tool data\n",
    "class DatasetCreator(Dataset):\n",
    "    def __init__(self, spec_path, labels_path, image_size, channels):\n",
    "        # Read the Labels file as a dataframe and store the paths to specX,Y,Z and tool in the same dataframe.\n",
    "        # Don't load the images now, requires lot of memory.\n",
    "        # Load in __getitem__()\n",
    "        self.df = pd.read_csv(labels_path, index_col=0)\n",
    "        self.df['specX'] = self.df.index.map(lambda id: f'{spec_path}/spec_x/{id}.png')\n",
    "        self.df['specY'] = self.df.index.map(lambda id: f'{spec_path}/spec_y/{id}.png')\n",
    "        self.df['specZ'] = self.df.index.map(lambda id: f'{spec_path}/spec_z/{id}.png')\n",
    "        self.df['tool'] = self.df.index.map(lambda id: f'{spec_path}/tool/{id}.jpg')\n",
    "        self.image_size = image_size\n",
    "        self.channels = channels\n",
    "\n",
    "    def __get_df__(self):\n",
    "        # Just for debugging purpose\n",
    "        return self.df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df.index)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # place holder for all the three images (each image has 3 channels)\n",
    "        image = torch.zeros((self.image_size, self.image_size, self.channels))\n",
    "\n",
    "        # idx_details has every think we need about the entry of that idx\n",
    "        idx_details = self.df.iloc[idx]\n",
    "\n",
    "        # Read images\n",
    "        # Note that we are not converting BGR to RGB because it doesn't matter to the NN\n",
    "        img_x = cv2.imread(idx_details['specX'])\n",
    "        res_x = cv2.resize(img_x, dsize=(image_size, image_size), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        img_y = cv2.imread(idx_details['specY'])\n",
    "        res_y = cv2.resize(img_y, dsize=(image_size, image_size), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        img_z = cv2.imread(idx_details['specZ'])\n",
    "        res_z = cv2.resize(img_z, dsize=(image_size, image_size), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        img_tool = cv2.imread(idx_details['tool'])\n",
    "        res_tool = cv2.resize(img_tool, dsize=(image_size, image_size), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        image = torch.cat((torch.tensor(res_x), torch.tensor(res_y), torch.tensor(res_z), torch.tensor(res_tool)), dim=2).float()\n",
    "\n",
    "        label = idx_details['tool_label']\n",
    "\n",
    "        # change image to CxHxW from HxWxC\n",
    "        return image.transpose(0, 2).transpose(1, 2), label -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#augmented dataset\n",
    "# data_path = \"./dataset_aug\"\n",
    "# labels_path = \"./labels_aug/random_distribution\"\n",
    "\n",
    "#original dataset\n",
    "data_path = \"./dataset_original\"\n",
    "labels_path = \"./labels_original/random_distribution\"\n",
    "\n",
    "train_dataset = DatasetCreator(data_path, os.path.join(labels_path, \"train.csv\"), image_size, 3)\n",
    "test_dataset = DatasetCreator(data_path, os.path.join(labels_path, \"test.csv\"), image_size, 3)\n",
    "val_dataset = DatasetCreator(data_path, os.path.join(labels_path, \"val.csv\"), image_size, 3)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410 48 54\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset), len(test_dataset), len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 12, 256, 256]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "imgs, labels = next(iter(train_dataloader))\n",
    "print(imgs.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_label</th>\n",
       "      <th>tool_label</th>\n",
       "      <th>specX</th>\n",
       "      <th>specY</th>\n",
       "      <th>specZ</th>\n",
       "      <th>tool</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T6R1B4</th>\n",
       "      <td>sharp</td>\n",
       "      <td>1</td>\n",
       "      <td>./dataset_original/spec_x/T6R1B4.png</td>\n",
       "      <td>./dataset_original/spec_y/T6R1B4.png</td>\n",
       "      <td>./dataset_original/spec_z/T6R1B4.png</td>\n",
       "      <td>./dataset_original/tool/T6R1B4.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T2R3B2</th>\n",
       "      <td>sharp</td>\n",
       "      <td>1</td>\n",
       "      <td>./dataset_original/spec_x/T2R3B2.png</td>\n",
       "      <td>./dataset_original/spec_y/T2R3B2.png</td>\n",
       "      <td>./dataset_original/spec_z/T2R3B2.png</td>\n",
       "      <td>./dataset_original/tool/T2R3B2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T9R11B1</th>\n",
       "      <td>used</td>\n",
       "      <td>2</td>\n",
       "      <td>./dataset_original/spec_x/T9R11B1.png</td>\n",
       "      <td>./dataset_original/spec_y/T9R11B1.png</td>\n",
       "      <td>./dataset_original/spec_z/T9R11B1.png</td>\n",
       "      <td>./dataset_original/tool/T9R11B1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T9R3B1</th>\n",
       "      <td>sharp</td>\n",
       "      <td>1</td>\n",
       "      <td>./dataset_original/spec_x/T9R3B1.png</td>\n",
       "      <td>./dataset_original/spec_y/T9R3B1.png</td>\n",
       "      <td>./dataset_original/spec_z/T9R3B1.png</td>\n",
       "      <td>./dataset_original/tool/T9R3B1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T6R2B4</th>\n",
       "      <td>sharp</td>\n",
       "      <td>1</td>\n",
       "      <td>./dataset_original/spec_x/T6R2B4.png</td>\n",
       "      <td>./dataset_original/spec_y/T6R2B4.png</td>\n",
       "      <td>./dataset_original/spec_z/T6R2B4.png</td>\n",
       "      <td>./dataset_original/tool/T6R2B4.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        image_label  tool_label                                  specX  \\\n",
       "id                                                                       \n",
       "T6R1B4        sharp           1   ./dataset_original/spec_x/T6R1B4.png   \n",
       "T2R3B2        sharp           1   ./dataset_original/spec_x/T2R3B2.png   \n",
       "T9R11B1        used           2  ./dataset_original/spec_x/T9R11B1.png   \n",
       "T9R3B1        sharp           1   ./dataset_original/spec_x/T9R3B1.png   \n",
       "T6R2B4        sharp           1   ./dataset_original/spec_x/T6R2B4.png   \n",
       "\n",
       "                                         specY  \\\n",
       "id                                               \n",
       "T6R1B4    ./dataset_original/spec_y/T6R1B4.png   \n",
       "T2R3B2    ./dataset_original/spec_y/T2R3B2.png   \n",
       "T9R11B1  ./dataset_original/spec_y/T9R11B1.png   \n",
       "T9R3B1    ./dataset_original/spec_y/T9R3B1.png   \n",
       "T6R2B4    ./dataset_original/spec_y/T6R2B4.png   \n",
       "\n",
       "                                         specZ  \\\n",
       "id                                               \n",
       "T6R1B4    ./dataset_original/spec_z/T6R1B4.png   \n",
       "T2R3B2    ./dataset_original/spec_z/T2R3B2.png   \n",
       "T9R11B1  ./dataset_original/spec_z/T9R11B1.png   \n",
       "T9R3B1    ./dataset_original/spec_z/T9R3B1.png   \n",
       "T6R2B4    ./dataset_original/spec_z/T6R2B4.png   \n",
       "\n",
       "                                        tool  \n",
       "id                                            \n",
       "T6R1B4    ./dataset_original/tool/T6R1B4.jpg  \n",
       "T2R3B2    ./dataset_original/tool/T2R3B2.jpg  \n",
       "T9R11B1  ./dataset_original/tool/T9R11B1.jpg  \n",
       "T9R3B1    ./dataset_original/tool/T9R3B1.jpg  \n",
       "T6R2B4    ./dataset_original/tool/T6R2B4.jpg  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = train_dataset.__get_df__()\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: import model definition from other ipynb files\n",
    "\n",
    "kernel = (3,3)\n",
    "patch = 32\n",
    "filters = 128\n",
    "depth = 4\n",
    "padding = (1,1)\n",
    "\n",
    "class DepthWiseConvolutionBlock(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.dconv = nn.Conv2d(in_channels=filters, out_channels=filters, kernel_size=kernel, stride=1, padding=padding, groups=filters)\n",
    "        self.activation1 = nn.GELU()\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=filters)\n",
    "        self.pconv = nn.Conv2d(in_channels=filters, out_channels=filters, kernel_size=1)\n",
    "        self.activation2 = nn.GELU()\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=filters)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = x\n",
    "        _ = self.dconv(x)\n",
    "        _ = x0 + self.bn1(self.activation1(_))\n",
    "        _ = self.pconv(_)\n",
    "        return self.bn2(self.activation2(_))\n",
    "    \n",
    "class BaseBlock(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=in_channel_spec, out_channels=filters, stride=patch, kernel_size=patch, padding=0)\n",
    "        self.activation = nn.GELU()\n",
    "        self.bn = nn.BatchNorm2d(num_features=filters)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _ = self.conv(x)\n",
    "        _ = self.activation(_)\n",
    "        return self.bn(_)\n",
    "    \n",
    "class SpectogramModel(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.model = None\n",
    "        layers = [BaseBlock()]\n",
    "        for i in range(depth):\n",
    "            layers.append(DepthWiseConvolutionBlock())\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        # CLassification\n",
    "        self.pool = nn.AdaptiveAvgPool2d(output_size=(1,1))\n",
    "        self.linear = nn.Linear(in_features=filters, out_features=num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        _ = self.model(x)\n",
    "        _ = self.pool(_)\n",
    "        _ = _.view(x.shape[0], -1)\n",
    "        return self.linear(_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_tool = (7,7)\n",
    "patch_tool = 28\n",
    "filters_tool = 512\n",
    "depth_tool = 4\n",
    "padding_tool = (3,3)\n",
    "\n",
    "class DepthWiseConvolutionBlockTool(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.dconv = nn.Conv2d(in_channels=filters_tool, out_channels=filters_tool, kernel_size=kernel_tool, stride=1, padding=padding_tool, groups=filters_tool)\n",
    "        self.activation1 = nn.GELU()\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=filters_tool)\n",
    "        self.pconv = nn.Conv2d(in_channels=filters_tool, out_channels=filters_tool, kernel_size=1)\n",
    "        self.activation2 = nn.GELU()\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=filters_tool)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = x\n",
    "        _ = self.dconv(x)\n",
    "        _ = x0 + self.bn1(self.activation1(_))\n",
    "        _ = self.pconv(_)\n",
    "        return self.bn2(self.activation2(_))\n",
    "    \n",
    "class BaseBlockTool(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=in_channel_tool, out_channels=filters_tool, stride=patch_tool, kernel_size=patch_tool, padding=0)\n",
    "        self.activation = nn.GELU()\n",
    "        self.bn = nn.BatchNorm2d(num_features=filters_tool)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _ = self.conv(x)\n",
    "        _ = self.activation(_)\n",
    "        return self.bn(_)\n",
    "\n",
    "class ToolModel(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.model = None\n",
    "        layers = [BaseBlockTool()]\n",
    "        for i in range(depth_tool):\n",
    "            layers.append(DepthWiseConvolutionBlockTool())\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        # CLassification\n",
    "        self.pool = nn.AdaptiveAvgPool2d(output_size=(1,1))\n",
    "        self.linear = nn.Linear(in_features=filters_tool, out_features=num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        _ = self.model(x)\n",
    "        _ = self.pool(_)\n",
    "        _ = _.view(x.shape[0], -1)\n",
    "        return self.linear(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Tool Parameters:\n",
      "model.0.conv.weight: requires_grad=False\n",
      "model.0.conv.bias: requires_grad=False\n",
      "model.0.bn.weight: requires_grad=False\n",
      "model.0.bn.bias: requires_grad=False\n",
      "model.1.dconv.weight: requires_grad=False\n",
      "model.1.dconv.bias: requires_grad=False\n",
      "model.1.bn1.weight: requires_grad=False\n",
      "model.1.bn1.bias: requires_grad=False\n",
      "model.1.pconv.weight: requires_grad=False\n",
      "model.1.pconv.bias: requires_grad=False\n",
      "model.1.bn2.weight: requires_grad=False\n",
      "model.1.bn2.bias: requires_grad=False\n",
      "model.2.dconv.weight: requires_grad=False\n",
      "model.2.dconv.bias: requires_grad=False\n",
      "model.2.bn1.weight: requires_grad=False\n",
      "model.2.bn1.bias: requires_grad=False\n",
      "model.2.pconv.weight: requires_grad=False\n",
      "model.2.pconv.bias: requires_grad=False\n",
      "model.2.bn2.weight: requires_grad=False\n",
      "model.2.bn2.bias: requires_grad=False\n",
      "model.3.dconv.weight: requires_grad=False\n",
      "model.3.dconv.bias: requires_grad=False\n",
      "model.3.bn1.weight: requires_grad=False\n",
      "model.3.bn1.bias: requires_grad=False\n",
      "model.3.pconv.weight: requires_grad=False\n",
      "model.3.pconv.bias: requires_grad=False\n",
      "model.3.bn2.weight: requires_grad=False\n",
      "model.3.bn2.bias: requires_grad=False\n",
      "model.4.dconv.weight: requires_grad=False\n",
      "model.4.dconv.bias: requires_grad=False\n",
      "model.4.bn1.weight: requires_grad=False\n",
      "model.4.bn1.bias: requires_grad=False\n",
      "model.4.pconv.weight: requires_grad=False\n",
      "model.4.pconv.bias: requires_grad=False\n",
      "model.4.bn2.weight: requires_grad=False\n",
      "model.4.bn2.bias: requires_grad=False\n",
      "linear.weight: requires_grad=False\n",
      "linear.bias: requires_grad=False\n",
      "\n",
      "Model Spec Parameters:\n",
      "model.0.conv.weight: requires_grad=False\n",
      "model.0.conv.bias: requires_grad=False\n",
      "model.0.bn.weight: requires_grad=False\n",
      "model.0.bn.bias: requires_grad=False\n",
      "model.1.dconv.weight: requires_grad=False\n",
      "model.1.dconv.bias: requires_grad=False\n",
      "model.1.bn1.weight: requires_grad=False\n",
      "model.1.bn1.bias: requires_grad=False\n",
      "model.1.pconv.weight: requires_grad=False\n",
      "model.1.pconv.bias: requires_grad=False\n",
      "model.1.bn2.weight: requires_grad=False\n",
      "model.1.bn2.bias: requires_grad=False\n",
      "model.2.dconv.weight: requires_grad=False\n",
      "model.2.dconv.bias: requires_grad=False\n",
      "model.2.bn1.weight: requires_grad=False\n",
      "model.2.bn1.bias: requires_grad=False\n",
      "model.2.pconv.weight: requires_grad=False\n",
      "model.2.pconv.bias: requires_grad=False\n",
      "model.2.bn2.weight: requires_grad=False\n",
      "model.2.bn2.bias: requires_grad=False\n",
      "model.3.dconv.weight: requires_grad=False\n",
      "model.3.dconv.bias: requires_grad=False\n",
      "model.3.bn1.weight: requires_grad=False\n",
      "model.3.bn1.bias: requires_grad=False\n",
      "model.3.pconv.weight: requires_grad=False\n",
      "model.3.pconv.bias: requires_grad=False\n",
      "model.3.bn2.weight: requires_grad=False\n",
      "model.3.bn2.bias: requires_grad=False\n",
      "model.4.dconv.weight: requires_grad=False\n",
      "model.4.dconv.bias: requires_grad=False\n",
      "model.4.bn1.weight: requires_grad=False\n",
      "model.4.bn1.bias: requires_grad=False\n",
      "model.4.pconv.weight: requires_grad=False\n",
      "model.4.pconv.bias: requires_grad=False\n",
      "model.4.bn2.weight: requires_grad=False\n",
      "model.4.bn2.bias: requires_grad=False\n",
      "linear.weight: requires_grad=False\n",
      "linear.bias: requires_grad=False\n"
     ]
    }
   ],
   "source": [
    "# Path to the models\n",
    "model_path = 'models_nonaug'\n",
    "\n",
    "# Load the models\n",
    "model_spec = SpectogramModel()\n",
    "model_spec.load_state_dict(torch.load(f\"{model_path}/model_d4.pth\"))\n",
    "model_spec = model_spec.to(device)\n",
    "\n",
    "# model_tool = SimpleCNN()\n",
    "model_tool = ToolModel()\n",
    "model_tool.load_state_dict(torch.load(f\"{model_path}/model.pth\"))\n",
    "model_tool = model_tool.to(device)\n",
    "\n",
    "# Freeze the models\n",
    "for param in model_spec.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model_tool.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Verify that the parameters are frozen\n",
    "print(\"Model Tool Parameters:\")\n",
    "for name, param in model_tool.named_parameters():\n",
    "    print(f\"{name}: requires_grad={param.requires_grad}\")\n",
    "\n",
    "print(\"\\nModel Spec Parameters:\")\n",
    "for name, param in model_spec.named_parameters():\n",
    "    print(f\"{name}: requires_grad={param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpectogramModel(\n",
       "  (model): Sequential(\n",
       "    (0): BaseBlock(\n",
       "      (conv): Conv2d(9, 128, kernel_size=(32, 32), stride=(32, 32))\n",
       "      (activation): GELU(approximate='none')\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): DepthWiseConvolutionBlock(\n",
       "      (dconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "      (activation1): GELU(approximate='none')\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (pconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (activation2): GELU(approximate='none')\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): DepthWiseConvolutionBlock(\n",
       "      (dconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "      (activation1): GELU(approximate='none')\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (pconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (activation2): GELU(approximate='none')\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): DepthWiseConvolutionBlock(\n",
       "      (dconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "      (activation1): GELU(approximate='none')\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (pconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (activation2): GELU(approximate='none')\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): DepthWiseConvolutionBlock(\n",
       "      (dconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "      (activation1): GELU(approximate='none')\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (pconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (activation2): GELU(approximate='none')\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (linear): Linear(in_features=128, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0930, device='cuda:0')\n",
      "tensor([2, 2, 0, 2, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 2, 1, 2, 1, 1, 0, 0, 2,\n",
      "        1, 1, 0, 0, 1, 2, 1, 2, 0, 1, 1, 1, 1, 1, 0, 1, 1, 2, 0, 0, 0, 0, 0, 2,\n",
      "        1, 1, 0, 0, 1, 2, 2, 1, 2, 2, 2, 0, 1, 2, 0, 1], device='cuda:0') tensor([[-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862],\n",
      "        [-0.0022, -0.0099, -0.0862]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Sanity Test Spec Model\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "x = torch.zeros((64, 9, 256, 256)).to(device)\n",
    "y = torch.randint(0, 3, (64, )).to(device)\n",
    "y_pred = model_spec(x)\n",
    "loss = loss_func(y_pred, y)\n",
    "# loss.backward() # comented since model weights are frozen, uncommenting should give error\n",
    "\n",
    "print(loss)\n",
    "print(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolModel(\n",
       "  (model): Sequential(\n",
       "    (0): BaseBlockTool(\n",
       "      (conv): Conv2d(3, 512, kernel_size=(28, 28), stride=(28, 28))\n",
       "      (activation): GELU(approximate='none')\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): DepthWiseConvolutionBlockTool(\n",
       "      (dconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "      (activation1): GELU(approximate='none')\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (pconv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (activation2): GELU(approximate='none')\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): DepthWiseConvolutionBlockTool(\n",
       "      (dconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "      (activation1): GELU(approximate='none')\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (pconv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (activation2): GELU(approximate='none')\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): DepthWiseConvolutionBlockTool(\n",
       "      (dconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "      (activation1): GELU(approximate='none')\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (pconv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (activation2): GELU(approximate='none')\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): DepthWiseConvolutionBlockTool(\n",
       "      (dconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "      (activation1): GELU(approximate='none')\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (pconv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (activation2): GELU(approximate='none')\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (linear): Linear(in_features=512, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1069, device='cuda:0')\n",
      "tensor([1, 2, 0, 1, 2, 1, 1, 0, 2, 2, 0, 2, 2, 0, 0, 0, 0, 1, 0, 0, 0, 2, 1, 2,\n",
      "        1, 1, 2, 2, 0, 2, 2, 0, 1, 0, 0, 1, 0, 2, 2, 1, 1, 0, 1, 0, 1, 2, 0, 2,\n",
      "        0, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 2, 0], device='cuda:0') tensor([[ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061],\n",
      "        [ 0.1344,  0.0665, -0.1061]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Sanity Test Tool Model\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "x = torch.zeros((64, 3, 256, 256)).to(device)\n",
    "y = torch.randint(0, 3, (64, )).to(device)\n",
    "y_pred = model_tool(x)\n",
    "loss = loss_func(y_pred, y)\n",
    "# loss.backward() # comented since model weights are frozen, uncommenting should give error\n",
    "\n",
    "print(loss)\n",
    "print(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi Modal Model Definition\n",
    "class MultimodalConvModel(nn.Module):\n",
    "    def __init__(self, model_tool, model_spec, num_classes):\n",
    "        super(MultimodalConvModel, self).__init__()\n",
    "\n",
    "        # Truncate the tool model\n",
    "        self.truncated_model_tool = nn.Sequential(*list(model_tool.children())[:-1]).to(device)\n",
    "\n",
    "        self.truncated_model_spec = nn.Sequential(*list(model_spec.children())[:-1]).to(device)\n",
    "\n",
    "        print(self.truncated_model_tool)\n",
    "        print(self.truncated_model_spec)\n",
    "\n",
    "        # Verify that the parameters are frozen\n",
    "        print(\"Model Tool Parameters:\")\n",
    "        for name, param in self.truncated_model_tool.named_parameters():\n",
    "            print(f\"{name}: requires_grad={param.requires_grad}\")\n",
    "\n",
    "        print(\"\\nModel Spec Parameters:\")\n",
    "        for name, param in self.truncated_model_spec.named_parameters():\n",
    "            print(f\"{name}: requires_grad={param.requires_grad}\")\n",
    "       \n",
    "\n",
    "        # Get the input shapes of the models\n",
    "        tool_input_shape = list(list(model_tool.children())[0][0].children())[0].weight.shape\n",
    "        print(tool_input_shape)\n",
    "\n",
    "        spec_input_shape = list(list(model_spec.children())[0][0].children())[0].weight.shape\n",
    "        print(spec_input_shape)\n",
    "\n",
    "        # Get the output shapes of the models\n",
    "        tool_output_dim = self.truncated_model_tool(torch.zeros(*tool_input_shape).to(device)).shape[1]\n",
    "        print(tool_output_dim)\n",
    "\n",
    "        spec_output_dim = self.truncated_model_spec(torch.zeros(*spec_input_shape).to(device)).shape[1]\n",
    "        print(spec_output_dim)\n",
    "\n",
    "        # GRU and classification layer\n",
    "        self.gru = nn.GRU(tool_output_dim + spec_output_dim, 256, dropout=0.1, batch_first=True)\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        tool_output = self.truncated_model_tool(x2)\n",
    "        spec_output = self.truncated_model_spec(x1)\n",
    "        merged_output = torch.cat([tool_output, spec_output], dim=1)\n",
    "        # print(merged_output.shape)\n",
    "        merged_output = merged_output.view(merged_output.size(0), merged_output.size(1))\n",
    "        # print(merged_output.shape)\n",
    "        gru_output, _ = self.gru(merged_output)\n",
    "        output = self.fc(gru_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): BaseBlockTool(\n",
      "      (conv): Conv2d(3, 512, kernel_size=(28, 28), stride=(28, 28))\n",
      "      (activation): GELU(approximate='none')\n",
      "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): DepthWiseConvolutionBlockTool(\n",
      "      (dconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "      (activation1): GELU(approximate='none')\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (pconv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (activation2): GELU(approximate='none')\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): DepthWiseConvolutionBlockTool(\n",
      "      (dconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "      (activation1): GELU(approximate='none')\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (pconv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (activation2): GELU(approximate='none')\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): DepthWiseConvolutionBlockTool(\n",
      "      (dconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "      (activation1): GELU(approximate='none')\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (pconv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (activation2): GELU(approximate='none')\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): DepthWiseConvolutionBlockTool(\n",
      "      (dconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "      (activation1): GELU(approximate='none')\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (pconv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (activation2): GELU(approximate='none')\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      ")\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): BaseBlock(\n",
      "      (conv): Conv2d(9, 128, kernel_size=(32, 32), stride=(32, 32))\n",
      "      (activation): GELU(approximate='none')\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): DepthWiseConvolutionBlock(\n",
      "      (dconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "      (activation1): GELU(approximate='none')\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (pconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (activation2): GELU(approximate='none')\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): DepthWiseConvolutionBlock(\n",
      "      (dconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "      (activation1): GELU(approximate='none')\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (pconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (activation2): GELU(approximate='none')\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): DepthWiseConvolutionBlock(\n",
      "      (dconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "      (activation1): GELU(approximate='none')\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (pconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (activation2): GELU(approximate='none')\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): DepthWiseConvolutionBlock(\n",
      "      (dconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "      (activation1): GELU(approximate='none')\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (pconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (activation2): GELU(approximate='none')\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      ")\n",
      "Model Tool Parameters:\n",
      "0.0.conv.weight: requires_grad=False\n",
      "0.0.conv.bias: requires_grad=False\n",
      "0.0.bn.weight: requires_grad=False\n",
      "0.0.bn.bias: requires_grad=False\n",
      "0.1.dconv.weight: requires_grad=False\n",
      "0.1.dconv.bias: requires_grad=False\n",
      "0.1.bn1.weight: requires_grad=False\n",
      "0.1.bn1.bias: requires_grad=False\n",
      "0.1.pconv.weight: requires_grad=False\n",
      "0.1.pconv.bias: requires_grad=False\n",
      "0.1.bn2.weight: requires_grad=False\n",
      "0.1.bn2.bias: requires_grad=False\n",
      "0.2.dconv.weight: requires_grad=False\n",
      "0.2.dconv.bias: requires_grad=False\n",
      "0.2.bn1.weight: requires_grad=False\n",
      "0.2.bn1.bias: requires_grad=False\n",
      "0.2.pconv.weight: requires_grad=False\n",
      "0.2.pconv.bias: requires_grad=False\n",
      "0.2.bn2.weight: requires_grad=False\n",
      "0.2.bn2.bias: requires_grad=False\n",
      "0.3.dconv.weight: requires_grad=False\n",
      "0.3.dconv.bias: requires_grad=False\n",
      "0.3.bn1.weight: requires_grad=False\n",
      "0.3.bn1.bias: requires_grad=False\n",
      "0.3.pconv.weight: requires_grad=False\n",
      "0.3.pconv.bias: requires_grad=False\n",
      "0.3.bn2.weight: requires_grad=False\n",
      "0.3.bn2.bias: requires_grad=False\n",
      "0.4.dconv.weight: requires_grad=False\n",
      "0.4.dconv.bias: requires_grad=False\n",
      "0.4.bn1.weight: requires_grad=False\n",
      "0.4.bn1.bias: requires_grad=False\n",
      "0.4.pconv.weight: requires_grad=False\n",
      "0.4.pconv.bias: requires_grad=False\n",
      "0.4.bn2.weight: requires_grad=False\n",
      "0.4.bn2.bias: requires_grad=False\n",
      "\n",
      "Model Spec Parameters:\n",
      "0.0.conv.weight: requires_grad=False\n",
      "0.0.conv.bias: requires_grad=False\n",
      "0.0.bn.weight: requires_grad=False\n",
      "0.0.bn.bias: requires_grad=False\n",
      "0.1.dconv.weight: requires_grad=False\n",
      "0.1.dconv.bias: requires_grad=False\n",
      "0.1.bn1.weight: requires_grad=False\n",
      "0.1.bn1.bias: requires_grad=False\n",
      "0.1.pconv.weight: requires_grad=False\n",
      "0.1.pconv.bias: requires_grad=False\n",
      "0.1.bn2.weight: requires_grad=False\n",
      "0.1.bn2.bias: requires_grad=False\n",
      "0.2.dconv.weight: requires_grad=False\n",
      "0.2.dconv.bias: requires_grad=False\n",
      "0.2.bn1.weight: requires_grad=False\n",
      "0.2.bn1.bias: requires_grad=False\n",
      "0.2.pconv.weight: requires_grad=False\n",
      "0.2.pconv.bias: requires_grad=False\n",
      "0.2.bn2.weight: requires_grad=False\n",
      "0.2.bn2.bias: requires_grad=False\n",
      "0.3.dconv.weight: requires_grad=False\n",
      "0.3.dconv.bias: requires_grad=False\n",
      "0.3.bn1.weight: requires_grad=False\n",
      "0.3.bn1.bias: requires_grad=False\n",
      "0.3.pconv.weight: requires_grad=False\n",
      "0.3.pconv.bias: requires_grad=False\n",
      "0.3.bn2.weight: requires_grad=False\n",
      "0.3.bn2.bias: requires_grad=False\n",
      "0.4.dconv.weight: requires_grad=False\n",
      "0.4.dconv.bias: requires_grad=False\n",
      "0.4.bn1.weight: requires_grad=False\n",
      "0.4.bn1.bias: requires_grad=False\n",
      "0.4.pconv.weight: requires_grad=False\n",
      "0.4.pconv.bias: requires_grad=False\n",
      "0.4.bn2.weight: requires_grad=False\n",
      "0.4.bn2.bias: requires_grad=False\n",
      "torch.Size([512, 3, 28, 28])\n",
      "torch.Size([128, 9, 32, 32])\n",
      "512\n",
      "128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "#init model, loss function, optimizer\n",
    "model = MultimodalConvModel(model_tool, model_spec, num_classes).to(device)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultimodalConvModel(\n",
       "  (truncated_model_tool): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): BaseBlockTool(\n",
       "        (conv): Conv2d(3, 512, kernel_size=(28, 28), stride=(28, 28))\n",
       "        (activation): GELU(approximate='none')\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): DepthWiseConvolutionBlockTool(\n",
       "        (dconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "        (activation1): GELU(approximate='none')\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (pconv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation2): GELU(approximate='none')\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): DepthWiseConvolutionBlockTool(\n",
       "        (dconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "        (activation1): GELU(approximate='none')\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (pconv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation2): GELU(approximate='none')\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): DepthWiseConvolutionBlockTool(\n",
       "        (dconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "        (activation1): GELU(approximate='none')\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (pconv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation2): GELU(approximate='none')\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): DepthWiseConvolutionBlockTool(\n",
       "        (dconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "        (activation1): GELU(approximate='none')\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (pconv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation2): GELU(approximate='none')\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (truncated_model_spec): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): BaseBlock(\n",
       "        (conv): Conv2d(9, 128, kernel_size=(32, 32), stride=(32, 32))\n",
       "        (activation): GELU(approximate='none')\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): DepthWiseConvolutionBlock(\n",
       "        (dconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "        (activation1): GELU(approximate='none')\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (pconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation2): GELU(approximate='none')\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): DepthWiseConvolutionBlock(\n",
       "        (dconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "        (activation1): GELU(approximate='none')\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (pconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation2): GELU(approximate='none')\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): DepthWiseConvolutionBlock(\n",
       "        (dconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "        (activation1): GELU(approximate='none')\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (pconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation2): GELU(approximate='none')\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): DepthWiseConvolutionBlock(\n",
       "        (dconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "        (activation1): GELU(approximate='none')\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (pconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation2): GELU(approximate='none')\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (gru): GRU(640, 256, batch_first=True, dropout=0.1)\n",
       "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and eval functions\n",
    "def train(model, dataloader, optimizer, loss_func, device):\n",
    "    model.train()\n",
    "    model = model.to(device)\n",
    "    total_loss, total_count, acc_count = 0, 0, 0\n",
    "\n",
    "    for idx, (X, y) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # print(X.shape)\n",
    "        # print(y.shape)\n",
    "\n",
    "        # Split X into input_tool and input_spec\n",
    "        input_spec = X[:, :in_channel_spec, ...]\n",
    "        input_tool = X[:, in_channel_spec:in_channel_spec + in_channel_tool, ...]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(input_spec, input_tool)\n",
    "        loss = loss_func(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Loss\n",
    "        total_loss += loss.item()\n",
    "        total_count += X.size(0) # Batch size\n",
    "\n",
    "        # Accuracy\n",
    "        _, y_pred_class = y_pred.max(dim=1)\n",
    "        acc_count += (y_pred_class == y).sum().item()\n",
    "\n",
    "    return total_loss/total_count, acc_count/total_count\n",
    "\n",
    "def evaluate(model, dataloader, loss_func, device):\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    total_loss, total_count, acc_count = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (X, y) in enumerate(dataloader):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # Split X into input_tool and input_spec\n",
    "            input_spec = X[:, :in_channel_spec, ...]\n",
    "            input_tool = X[:, in_channel_spec:in_channel_spec + in_channel_tool, ...]\n",
    "\n",
    "            y_pred = model(input_spec, input_tool)\n",
    "            loss = loss_func(y_pred, y)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_count += X.size(0)\n",
    "\n",
    "            # Accuracy\n",
    "            _, y_pred_class = y_pred.max(dim=1)\n",
    "            acc_count += (y_pred_class == y).sum().item()\n",
    "\n",
    "    return total_loss/total_count, acc_count/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started new epoch ..\n",
      "======================================================================================================\n",
      "| Epoch 1/10 | time: 16.630 | Train Loss: 0.009 | Val Loss: 0.016 | Train Acc: 0.834 | Val Acc: 0.759 |\n",
      "started new epoch ..\n",
      "======================================================================================================\n",
      "| Epoch 2/10 | time: 15.586 | Train Loss: 0.002 | Val Loss: 0.009 | Train Acc: 0.968 | Val Acc: 0.759 |\n",
      "started new epoch ..\n",
      "======================================================================================================\n",
      "| Epoch 3/10 | time: 14.914 | Train Loss: 0.001 | Val Loss: 0.008 | Train Acc: 0.985 | Val Acc: 0.815 |\n",
      "started new epoch ..\n",
      "======================================================================================================\n",
      "| Epoch 4/10 | time: 14.860 | Train Loss: 0.001 | Val Loss: 0.007 | Train Acc: 0.993 | Val Acc: 0.852 |\n",
      "started new epoch ..\n",
      "======================================================================================================\n",
      "| Epoch 5/10 | time: 14.834 | Train Loss: 0.000 | Val Loss: 0.005 | Train Acc: 0.998 | Val Acc: 0.889 |\n",
      "started new epoch ..\n",
      "======================================================================================================\n",
      "| Epoch 6/10 | time: 15.195 | Train Loss: 0.000 | Val Loss: 0.005 | Train Acc: 0.998 | Val Acc: 0.907 |\n",
      "started new epoch ..\n",
      "======================================================================================================\n",
      "| Epoch 7/10 | time: 14.803 | Train Loss: 0.000 | Val Loss: 0.005 | Train Acc: 1.000 | Val Acc: 0.907 |\n",
      "started new epoch ..\n",
      "======================================================================================================\n",
      "| Epoch 8/10 | time: 15.701 | Train Loss: 0.000 | Val Loss: 0.006 | Train Acc: 1.000 | Val Acc: 0.907 |\n",
      "started new epoch ..\n",
      "======================================================================================================\n",
      "| Epoch 9/10 | time: 15.094 | Train Loss: 0.000 | Val Loss: 0.006 | Train Acc: 1.000 | Val Acc: 0.944 |\n",
      "started new epoch ..\n",
      "======================================================================================================\n",
      "| Epoch 10/10 | time: 15.209 | Train Loss: 0.000 | Val Loss: 0.006 | Train Acc: 1.000 | Val Acc: 0.944 |\n"
     ]
    }
   ],
   "source": [
    "#training loop\n",
    "train_loss_epochs = []\n",
    "val_loss_epochs = []\n",
    "train_acc_epochs = []\n",
    "val_acc_epochs = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start = time.time()\n",
    "    print(\"started new epoch ..\")\n",
    "    loss_train, train_acc = train(model, train_dataloader, optimizer, loss_func, device)\n",
    "    loss_val, val_acc = evaluate(model, val_dataloader, loss_func, device)\n",
    "\n",
    "    train_loss_epochs.append(loss_train)\n",
    "    val_loss_epochs.append(loss_val)\n",
    "    train_acc_epochs.append(train_acc)\n",
    "    val_acc_epochs.append(val_acc)\n",
    "    end = time.time()\n",
    "\n",
    "    print(\"=\" * 102)\n",
    "    print(f\"| Epoch {epoch+1}/{num_epochs} | time: {(end-start):.3f} | Train Loss: {loss_train:.3f} | Val Loss: {loss_val:.3f} | Train Acc: {train_acc:.3f} | Val Acc: {val_acc:.3f} |\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.875\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model, test_dataloader, loss_func, device)\n",
    "print(\"Test Accuracy: \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save loss and accuracy\n",
    "torch.save(model.state_dict(), \"models_nonaug/rnn_model\")\n",
    "torch.save(train_loss_epochs, \"output/train_loss_epochs.pt\")\n",
    "torch.save(val_loss_epochs, \"output/val_loss_epochs.pt\")\n",
    "torch.save(train_acc_epochs, \"output/train_acc_epochs.pt\")\n",
    "torch.save(val_acc_epochs, \"output/val_acc_epochs.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot Epoch vs. Loss\n",
    "plt.plot(train_loss_epochs, label=\"Train\")\n",
    "plt.plot(val_loss_epochs, label=\"Validation\")\n",
    "plt.title(\"Epoch vs Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "#plot Epoch vs. Accuracy\n",
    "plt.plot(train_acc_epochs, label=\"Train\")\n",
    "plt.plot(val_acc_epochs, label=\"Validation\")\n",
    "plt.title(\"Epoch vs Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables\n",
    "image_size = 256\n",
    "in_channel_spec = 9\n",
    "in_channel_tool = 3\n",
    "num_classes = 3\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 64\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DatasetCreator for combined spec and tool data\n",
    "class DatasetCreator(Dataset):\n",
    "    def __init__(self, spec_path, labels_path, image_size, channels):\n",
    "        # Read the Labels file as a dataframe and store the paths to specX,Y,Z and tool in the same dataframe.\n",
    "        # Don't load the images now, requires lot of memory.\n",
    "        # Load in __getitem__()\n",
    "        self.df = pd.read_csv(labels_path, index_col=0)\n",
    "        self.df['specX'] = self.df.index.map(lambda id: f'{spec_path}/specX/{id}.png')\n",
    "        self.df['specY'] = self.df.index.map(lambda id: f'{spec_path}/specY/{id}.png')\n",
    "        self.df['specZ'] = self.df.index.map(lambda id: f'{spec_path}/specZ/{id}.png')\n",
    "        self.df['tool'] = self.df.index.map(lambda id: f'{spec_path}/tool/{id}.jpg')\n",
    "        self.image_size = image_size\n",
    "        self.channels = channels\n",
    "\n",
    "    def __get_df__(self):\n",
    "        # Just for debugging purpose\n",
    "        return self.df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df.index)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # place holder for all the three images (each image has 3 channels)\n",
    "        image = torch.zeros((self.image_size, self.image_size, self.channels))\n",
    "\n",
    "        # idx_details has every think we need about the entry of that idx\n",
    "        idx_details = self.df.iloc[idx]\n",
    "\n",
    "        # Read images\n",
    "        # Note that we are not converting BGR to RGB because it doesn't matter to the NN\n",
    "        img_x = cv2.imread(idx_details['specX'])\n",
    "        res_x = cv2.resize(img_x, dsize=(image_size, image_size), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        img_y = cv2.imread(idx_details['specY'])\n",
    "        res_y = cv2.resize(img_y, dsize=(image_size, image_size), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        img_z = cv2.imread(idx_details['specZ'])\n",
    "        res_z = cv2.resize(img_z, dsize=(image_size, image_size), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        img_tool = cv2.imread(idx_details['tool'])\n",
    "        res_tool = cv2.resize(img_tool, dsize=(image_size, image_size), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        image = torch.cat((torch.tensor(res_x), torch.tensor(res_y), torch.tensor(res_z), torch.tensor(res_tool)), dim=2).float()\n",
    "\n",
    "        label = idx_details['tool_label']\n",
    "\n",
    "        # change image to CxHxW from HxWxC\n",
    "        return image.transpose(0, 2).transpose(1, 2), label -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./dataset_aug\"\n",
    "labels_path = \"./labels_aug/random_distribution\"\n",
    "\n",
    "train_dataset = DatasetCreator(data_path, os.path.join(labels_path, \"train.csv\"), image_size, 3)\n",
    "test_dataset = DatasetCreator(data_path, os.path.join(labels_path, \"test.csv\"), image_size, 3)\n",
    "val_dataset = DatasetCreator(data_path, os.path.join(labels_path, \"val.csv\"), image_size, 3)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2460 48 54\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset), len(test_dataset), len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 12, 256, 256]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "imgs, labels = next(iter(train_dataloader))\n",
    "print(imgs.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_label</th>\n",
       "      <th>tool_label</th>\n",
       "      <th>specX</th>\n",
       "      <th>specY</th>\n",
       "      <th>specZ</th>\n",
       "      <th>tool</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T6R1B4</th>\n",
       "      <td>sharp</td>\n",
       "      <td>1</td>\n",
       "      <td>./dataset_aug/specX/T6R1B4.png</td>\n",
       "      <td>./dataset_aug/specY/T6R1B4.png</td>\n",
       "      <td>./dataset_aug/specZ/T6R1B4.png</td>\n",
       "      <td>./dataset_aug/tool/T6R1B4.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T2R3B2</th>\n",
       "      <td>sharp</td>\n",
       "      <td>1</td>\n",
       "      <td>./dataset_aug/specX/T2R3B2.png</td>\n",
       "      <td>./dataset_aug/specY/T2R3B2.png</td>\n",
       "      <td>./dataset_aug/specZ/T2R3B2.png</td>\n",
       "      <td>./dataset_aug/tool/T2R3B2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T9R11B1</th>\n",
       "      <td>used</td>\n",
       "      <td>2</td>\n",
       "      <td>./dataset_aug/specX/T9R11B1.png</td>\n",
       "      <td>./dataset_aug/specY/T9R11B1.png</td>\n",
       "      <td>./dataset_aug/specZ/T9R11B1.png</td>\n",
       "      <td>./dataset_aug/tool/T9R11B1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T9R3B1</th>\n",
       "      <td>sharp</td>\n",
       "      <td>1</td>\n",
       "      <td>./dataset_aug/specX/T9R3B1.png</td>\n",
       "      <td>./dataset_aug/specY/T9R3B1.png</td>\n",
       "      <td>./dataset_aug/specZ/T9R3B1.png</td>\n",
       "      <td>./dataset_aug/tool/T9R3B1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T6R2B4</th>\n",
       "      <td>sharp</td>\n",
       "      <td>1</td>\n",
       "      <td>./dataset_aug/specX/T6R2B4.png</td>\n",
       "      <td>./dataset_aug/specY/T6R2B4.png</td>\n",
       "      <td>./dataset_aug/specZ/T6R2B4.png</td>\n",
       "      <td>./dataset_aug/tool/T6R2B4.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        image_label  tool_label                            specX  \\\n",
       "id                                                                 \n",
       "T6R1B4        sharp           1   ./dataset_aug/specX/T6R1B4.png   \n",
       "T2R3B2        sharp           1   ./dataset_aug/specX/T2R3B2.png   \n",
       "T9R11B1        used           2  ./dataset_aug/specX/T9R11B1.png   \n",
       "T9R3B1        sharp           1   ./dataset_aug/specX/T9R3B1.png   \n",
       "T6R2B4        sharp           1   ./dataset_aug/specX/T6R2B4.png   \n",
       "\n",
       "                                   specY                            specZ  \\\n",
       "id                                                                          \n",
       "T6R1B4    ./dataset_aug/specY/T6R1B4.png   ./dataset_aug/specZ/T6R1B4.png   \n",
       "T2R3B2    ./dataset_aug/specY/T2R3B2.png   ./dataset_aug/specZ/T2R3B2.png   \n",
       "T9R11B1  ./dataset_aug/specY/T9R11B1.png  ./dataset_aug/specZ/T9R11B1.png   \n",
       "T9R3B1    ./dataset_aug/specY/T9R3B1.png   ./dataset_aug/specZ/T9R3B1.png   \n",
       "T6R2B4    ./dataset_aug/specY/T6R2B4.png   ./dataset_aug/specZ/T6R2B4.png   \n",
       "\n",
       "                                   tool  \n",
       "id                                       \n",
       "T6R1B4    ./dataset_aug/tool/T6R1B4.jpg  \n",
       "T2R3B2    ./dataset_aug/tool/T2R3B2.jpg  \n",
       "T9R11B1  ./dataset_aug/tool/T9R11B1.jpg  \n",
       "T9R3B1    ./dataset_aug/tool/T9R3B1.jpg  \n",
       "T6R2B4    ./dataset_aug/tool/T6R2B4.jpg  "
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = train_dataset.__get_df__()\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: import model definition from other ipynb files\n",
    "\n",
    "kernel = (3,3)\n",
    "patch = 32\n",
    "filters = 128\n",
    "depth = 4\n",
    "padding = (1,1)\n",
    "\n",
    "class DepthWiseConvolutionBlock(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.dconv = nn.Conv2d(in_channels=filters, out_channels=filters, kernel_size=kernel, stride=1, padding=padding, groups=filters)\n",
    "        self.activation1 = nn.GELU()\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=filters)\n",
    "        self.pconv = nn.Conv2d(in_channels=filters, out_channels=filters, kernel_size=1)\n",
    "        self.activation2 = nn.GELU()\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=filters)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = x\n",
    "        _ = self.dconv(x)\n",
    "        _ = x0 + self.bn1(self.activation1(_))\n",
    "        _ = self.pconv(_)\n",
    "        return self.bn2(self.activation2(_))\n",
    "    \n",
    "class BaseBlock(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=in_channel_spec, out_channels=filters, stride=patch, kernel_size=patch, padding=0)\n",
    "        self.activation = nn.GELU()\n",
    "        self.bn = nn.BatchNorm2d(num_features=filters)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _ = self.conv(x)\n",
    "        _ = self.activation(_)\n",
    "        return self.bn(_)\n",
    "    \n",
    "class ClassificationBlock(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d(output_size=(1,1))\n",
    "        self.linear = nn.Linear(in_features=filters, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        _ = self.pool(x)\n",
    "        # print(f\"After Avg Pooling: {_.shape}\")\n",
    "        _ = _.view(x.shape[0], -1)\n",
    "        return self.linear(_)\n",
    "    \n",
    "class SpectogramModel(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.model = None\n",
    "        layers = [BaseBlock()]\n",
    "        for i in range(depth):\n",
    "            layers.append(DepthWiseConvolutionBlock())\n",
    "        layers.append(ClassificationBlock())\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=3, cnn_out_channels=64):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, cnn_out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(cnn_out_channels)\n",
    "        self.conv2 = nn.Conv2d(cnn_out_channels, cnn_out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(cnn_out_channels)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(cnn_out_channels * (image_size // 4) ** 2, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Tool Parameters:\n",
      "conv1.weight: requires_grad=False\n",
      "conv1.bias: requires_grad=False\n",
      "bn1.weight: requires_grad=False\n",
      "bn1.bias: requires_grad=False\n",
      "conv2.weight: requires_grad=False\n",
      "conv2.bias: requires_grad=False\n",
      "bn2.weight: requires_grad=False\n",
      "bn2.bias: requires_grad=False\n",
      "fc1.weight: requires_grad=False\n",
      "fc1.bias: requires_grad=False\n",
      "fc2.weight: requires_grad=False\n",
      "fc2.bias: requires_grad=False\n",
      "\n",
      "Model Spec Parameters:\n",
      "model.0.conv.weight: requires_grad=False\n",
      "model.0.conv.bias: requires_grad=False\n",
      "model.0.bn.weight: requires_grad=False\n",
      "model.0.bn.bias: requires_grad=False\n",
      "model.1.dconv.weight: requires_grad=False\n",
      "model.1.dconv.bias: requires_grad=False\n",
      "model.1.bn1.weight: requires_grad=False\n",
      "model.1.bn1.bias: requires_grad=False\n",
      "model.1.pconv.weight: requires_grad=False\n",
      "model.1.pconv.bias: requires_grad=False\n",
      "model.1.bn2.weight: requires_grad=False\n",
      "model.1.bn2.bias: requires_grad=False\n",
      "model.2.dconv.weight: requires_grad=False\n",
      "model.2.dconv.bias: requires_grad=False\n",
      "model.2.bn1.weight: requires_grad=False\n",
      "model.2.bn1.bias: requires_grad=False\n",
      "model.2.pconv.weight: requires_grad=False\n",
      "model.2.pconv.bias: requires_grad=False\n",
      "model.2.bn2.weight: requires_grad=False\n",
      "model.2.bn2.bias: requires_grad=False\n",
      "model.3.dconv.weight: requires_grad=False\n",
      "model.3.dconv.bias: requires_grad=False\n",
      "model.3.bn1.weight: requires_grad=False\n",
      "model.3.bn1.bias: requires_grad=False\n",
      "model.3.pconv.weight: requires_grad=False\n",
      "model.3.pconv.bias: requires_grad=False\n",
      "model.3.bn2.weight: requires_grad=False\n",
      "model.3.bn2.bias: requires_grad=False\n",
      "model.4.dconv.weight: requires_grad=False\n",
      "model.4.dconv.bias: requires_grad=False\n",
      "model.4.bn1.weight: requires_grad=False\n",
      "model.4.bn1.bias: requires_grad=False\n",
      "model.4.pconv.weight: requires_grad=False\n",
      "model.4.pconv.bias: requires_grad=False\n",
      "model.4.bn2.weight: requires_grad=False\n",
      "model.4.bn2.bias: requires_grad=False\n",
      "model.5.linear.weight: requires_grad=False\n",
      "model.5.linear.bias: requires_grad=False\n"
     ]
    }
   ],
   "source": [
    "# Path to the models\n",
    "model_path = 'models'\n",
    "\n",
    "# Load the models\n",
    "model_spec = SpectogramModel()\n",
    "model_spec.load_state_dict(torch.load(f\"{model_path}/model_d4.pth\"))\n",
    "model_spec = model_spec.to(device)\n",
    "\n",
    "model_tool = SimpleCNN()\n",
    "model_tool.load_state_dict(torch.load(f\"{model_path}/tool_model.pth\"))\n",
    "model_tool = model_tool.to(device)\n",
    "\n",
    "# Freeze the models\n",
    "for param in model_spec.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model_tool.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Verify that the parameters are frozen\n",
    "print(\"Model Tool Parameters:\")\n",
    "for name, param in model_tool.named_parameters():\n",
    "    print(f\"{name}: requires_grad={param.requires_grad}\")\n",
    "\n",
    "print(\"\\nModel Spec Parameters:\")\n",
    "for name, param in model_spec.named_parameters():\n",
    "    print(f\"{name}: requires_grad={param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpectogramModel(\n",
       "  (model): Sequential(\n",
       "    (0): BaseBlock(\n",
       "      (conv): Conv2d(9, 128, kernel_size=(32, 32), stride=(32, 32))\n",
       "      (activation): GELU(approximate='none')\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): DepthWiseConvolutionBlock(\n",
       "      (dconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "      (activation1): GELU(approximate='none')\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (pconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (activation2): GELU(approximate='none')\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): DepthWiseConvolutionBlock(\n",
       "      (dconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "      (activation1): GELU(approximate='none')\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (pconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (activation2): GELU(approximate='none')\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): DepthWiseConvolutionBlock(\n",
       "      (dconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "      (activation1): GELU(approximate='none')\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (pconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (activation2): GELU(approximate='none')\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): DepthWiseConvolutionBlock(\n",
       "      (dconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "      (activation1): GELU(approximate='none')\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (pconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (activation2): GELU(approximate='none')\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): ClassificationBlock(\n",
       "      (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (linear): Linear(in_features=128, out_features=3, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1011, device='cuda:0')\n",
      "tensor([1, 1, 0, 2, 2, 2, 1, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 2, 0,\n",
      "        0, 2, 2, 1, 2, 1, 0, 0, 0, 1, 2, 0, 1, 1, 1, 2, 1, 1, 1, 2, 2, 0, 0, 1,\n",
      "        0, 1, 2, 1, 0, 2, 0, 2, 2, 2, 2, 1, 1, 1, 0, 0], device='cuda:0') tensor([[ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325],\n",
      "        [ 0.0543,  0.0409, -0.1325]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Sanity Test Spec Model\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "x = torch.zeros((64, 9, 256, 256)).to(device)\n",
    "y = torch.randint(0, 3, (64, )).to(device)\n",
    "y_pred = model_spec(x)\n",
    "loss = loss_func(y_pred, y)\n",
    "# loss.backward() # comented since model weights are frozen, uncommenting should give error\n",
    "\n",
    "print(loss)\n",
    "print(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=262144, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1494, device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') tensor([[ 3.6968,  0.9522, -0.7792],\n",
      "        [ 3.3157,  0.8322, -0.6677],\n",
      "        [ 2.9819,  1.0557, -0.8924],\n",
      "        [ 2.6359,  0.5192, -0.0920],\n",
      "        [ 2.7573,  0.9817, -0.8215],\n",
      "        [ 3.2740,  0.7856, -0.6745],\n",
      "        [ 2.9525,  1.0974, -0.9150],\n",
      "        [ 3.3104,  0.8589, -0.7141],\n",
      "        [ 3.5443,  1.1042, -0.9698],\n",
      "        [ 3.1824,  1.1045, -1.0115],\n",
      "        [ 2.7473,  0.9229, -0.7754],\n",
      "        [ 3.0174,  0.9283, -0.7555],\n",
      "        [ 2.9445,  0.8635, -0.7171],\n",
      "        [ 3.0145,  0.9278, -0.8213],\n",
      "        [ 2.9210,  1.1527, -1.0459],\n",
      "        [ 2.4338,  1.1899, -1.0510],\n",
      "        [ 2.5831,  0.8337, -0.5684],\n",
      "        [ 2.7354,  1.0749, -0.9169],\n",
      "        [ 3.1055,  0.8579, -0.7253],\n",
      "        [ 2.9754,  0.9082, -0.7839],\n",
      "        [ 3.0038,  1.0314, -0.9053],\n",
      "        [ 2.7568,  0.7186, -0.5514],\n",
      "        [ 3.2266,  0.9841, -0.8008],\n",
      "        [ 2.9901,  0.9612, -0.7915],\n",
      "        [ 3.0275,  1.0337, -0.8955],\n",
      "        [ 3.2279,  1.0542, -0.9042],\n",
      "        [ 2.6345,  0.8032, -0.5913],\n",
      "        [ 3.0982,  1.0817, -0.8871],\n",
      "        [ 2.8034,  0.9473, -0.7977],\n",
      "        [ 3.0533,  0.8690, -0.7599],\n",
      "        [ 2.6252,  1.1147, -0.9667],\n",
      "        [ 3.1522,  0.4883, -0.3185],\n",
      "        [ 3.4525,  0.8057, -0.6270],\n",
      "        [ 3.0206,  0.8519, -0.7142],\n",
      "        [ 2.8899,  1.0476, -0.8562],\n",
      "        [ 2.6914,  0.6771, -0.5029],\n",
      "        [ 2.5452,  0.9525, -0.8355],\n",
      "        [ 3.5695,  0.8783, -0.7278],\n",
      "        [ 2.5728,  0.8922, -0.7282],\n",
      "        [ 2.9566,  0.7825, -0.6328],\n",
      "        [ 2.7404,  1.1213, -0.9409],\n",
      "        [ 3.1102,  0.8136, -0.6745],\n",
      "        [ 2.6090,  0.9231, -0.8095],\n",
      "        [ 2.7735,  1.0239, -0.8168],\n",
      "        [ 2.9693,  1.0454, -0.8901],\n",
      "        [ 2.5348,  0.9182, -0.7443],\n",
      "        [ 2.5892,  0.8506, -0.5335],\n",
      "        [ 3.0317,  1.1372, -0.9504],\n",
      "        [ 2.8579,  1.0248, -0.8924],\n",
      "        [ 2.8200,  0.9185, -0.7594],\n",
      "        [ 3.0331,  0.7556, -0.6000],\n",
      "        [ 2.6553,  0.8450, -0.7218],\n",
      "        [ 3.1908,  0.9081, -0.7682],\n",
      "        [ 3.1360,  0.9655, -0.8245],\n",
      "        [ 2.7476,  0.8995, -0.7669],\n",
      "        [ 3.1817,  0.9125, -0.7572],\n",
      "        [ 3.2607,  0.8708, -0.7505],\n",
      "        [ 3.2589,  0.9761, -0.8355],\n",
      "        [ 3.3458,  0.9318, -0.7680],\n",
      "        [ 3.4825,  1.0582, -0.9232],\n",
      "        [ 2.8747,  0.9475, -0.8138],\n",
      "        [ 2.8410,  0.9875, -0.8584],\n",
      "        [ 2.5011,  0.9232, -0.7171],\n",
      "        [ 3.0205,  0.9939, -0.8580]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Sanity Test Tool Model\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "x = torch.zeros((64, 3, 256, 256)).to(device)\n",
    "y = torch.randint(0, 1, (64, )).to(device)\n",
    "y_pred = model_tool(x)\n",
    "loss = loss_func(y_pred, y)\n",
    "# loss.backward() # comented since model weights are frozen, uncommenting should give error\n",
    "\n",
    "print(loss)\n",
    "print(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi Modal Model Definition\n",
    "class MultimodalConvModel(nn.Module):\n",
    "    def __init__(self, model_tool, model_spec, num_classes):\n",
    "        super(MultimodalConvModel, self).__init__()\n",
    "\n",
    "        # Truncate the tool model\n",
    "        self.truncated_model_tool = nn.Sequential(*list(model_tool.children())[:-3]).to(device)\n",
    "\n",
    "        # truncate the spec model\n",
    "        self.truncated_model_spec = nn.Sequential(*list(*list(model_spec.children()))[:-1]).to(device)\n",
    "\n",
    "        # TODO: get flattened models with correct output shapes from both models directly, instead of this hack\n",
    "        self.pool = nn.AdaptiveAvgPool2d(output_size=(1,1))\n",
    "\n",
    "        print(self.truncated_model_tool)\n",
    "        print(self.truncated_model_spec)\n",
    "\n",
    "        # Verify that the parameters are frozen\n",
    "        print(\"Model Tool Parameters:\")\n",
    "        for name, param in self.truncated_model_tool.named_parameters():\n",
    "            print(f\"{name}: requires_grad={param.requires_grad}\")\n",
    "\n",
    "        print(\"\\nModel Spec Parameters:\")\n",
    "        for name, param in self.truncated_model_spec.named_parameters():\n",
    "            print(f\"{name}: requires_grad={param.requires_grad}\")\n",
    "       \n",
    "\n",
    "        # Get the input shapes of the models\n",
    "        tool_input_shape = list(model_tool.children())[0].weight.shape\n",
    "        print(tool_input_shape)\n",
    "\n",
    "        spec_input_shape = list(list(model_spec.children())[0][0].children())[0].weight.shape\n",
    "        print(spec_input_shape)\n",
    "\n",
    "        # Get the output shapes of the models\n",
    "        tool_output_dim = self.truncated_model_tool(torch.zeros(*tool_input_shape).to(device)).shape[1]\n",
    "        print(tool_output_dim)\n",
    "\n",
    "        spec_output_dim = self.truncated_model_spec(torch.zeros(*spec_input_shape).to(device)).shape[1]\n",
    "        print(spec_output_dim)\n",
    "\n",
    "        # GRU and classification layer\n",
    "        self.gru = nn.GRU(tool_output_dim + spec_output_dim, 256, dropout=0.1, batch_first=True)\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        tool_output = self.truncated_model_tool(x2)\n",
    "        spec_output = self.truncated_model_spec(x1)\n",
    "        spec_output = self.pool(spec_output)\n",
    "        tool_output = self.pool(tool_output)\n",
    "        # print(tool_output.shape)\n",
    "        # print(spec_output.shape)\n",
    "        merged_output = torch.cat([tool_output, spec_output], dim=1)\n",
    "        # print(merged_output.shape)\n",
    "        merged_output = merged_output.view(merged_output.size(0), merged_output.size(1))\n",
    "        # print(merged_output.shape)\n",
    "        gru_output, _ = self.gru(merged_output)\n",
    "        output = self.fc(gru_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "Sequential(\n",
      "  (0): BaseBlock(\n",
      "    (conv): Conv2d(9, 128, kernel_size=(32, 32), stride=(32, 32))\n",
      "    (activation): GELU(approximate='none')\n",
      "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (1): DepthWiseConvolutionBlock(\n",
      "    (dconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "    (activation1): GELU(approximate='none')\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (pconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (activation2): GELU(approximate='none')\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (2): DepthWiseConvolutionBlock(\n",
      "    (dconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "    (activation1): GELU(approximate='none')\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (pconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (activation2): GELU(approximate='none')\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (3): DepthWiseConvolutionBlock(\n",
      "    (dconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "    (activation1): GELU(approximate='none')\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (pconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (activation2): GELU(approximate='none')\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (4): DepthWiseConvolutionBlock(\n",
      "    (dconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "    (activation1): GELU(approximate='none')\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (pconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (activation2): GELU(approximate='none')\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "Model Tool Parameters:\n",
      "0.weight: requires_grad=False\n",
      "0.bias: requires_grad=False\n",
      "1.weight: requires_grad=False\n",
      "1.bias: requires_grad=False\n",
      "2.weight: requires_grad=False\n",
      "2.bias: requires_grad=False\n",
      "3.weight: requires_grad=False\n",
      "3.bias: requires_grad=False\n",
      "\n",
      "Model Spec Parameters:\n",
      "0.conv.weight: requires_grad=False\n",
      "0.conv.bias: requires_grad=False\n",
      "0.bn.weight: requires_grad=False\n",
      "0.bn.bias: requires_grad=False\n",
      "1.dconv.weight: requires_grad=False\n",
      "1.dconv.bias: requires_grad=False\n",
      "1.bn1.weight: requires_grad=False\n",
      "1.bn1.bias: requires_grad=False\n",
      "1.pconv.weight: requires_grad=False\n",
      "1.pconv.bias: requires_grad=False\n",
      "1.bn2.weight: requires_grad=False\n",
      "1.bn2.bias: requires_grad=False\n",
      "2.dconv.weight: requires_grad=False\n",
      "2.dconv.bias: requires_grad=False\n",
      "2.bn1.weight: requires_grad=False\n",
      "2.bn1.bias: requires_grad=False\n",
      "2.pconv.weight: requires_grad=False\n",
      "2.pconv.bias: requires_grad=False\n",
      "2.bn2.weight: requires_grad=False\n",
      "2.bn2.bias: requires_grad=False\n",
      "3.dconv.weight: requires_grad=False\n",
      "3.dconv.bias: requires_grad=False\n",
      "3.bn1.weight: requires_grad=False\n",
      "3.bn1.bias: requires_grad=False\n",
      "3.pconv.weight: requires_grad=False\n",
      "3.pconv.bias: requires_grad=False\n",
      "3.bn2.weight: requires_grad=False\n",
      "3.bn2.bias: requires_grad=False\n",
      "4.dconv.weight: requires_grad=False\n",
      "4.dconv.bias: requires_grad=False\n",
      "4.bn1.weight: requires_grad=False\n",
      "4.bn1.bias: requires_grad=False\n",
      "4.pconv.weight: requires_grad=False\n",
      "4.pconv.bias: requires_grad=False\n",
      "4.bn2.weight: requires_grad=False\n",
      "4.bn2.bias: requires_grad=False\n",
      "torch.Size([64, 3, 3, 3])\n",
      "torch.Size([128, 9, 32, 32])\n",
      "64\n",
      "128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "#init model, loss function, optimizer\n",
    "model = MultimodalConvModel(model_tool, model_spec, num_classes).to(device)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultimodalConvModel(\n",
       "  (truncated_model_tool): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (truncated_model_spec): Sequential(\n",
       "    (0): BaseBlock(\n",
       "      (conv): Conv2d(9, 128, kernel_size=(32, 32), stride=(32, 32))\n",
       "      (activation): GELU(approximate='none')\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): DepthWiseConvolutionBlock(\n",
       "      (dconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "      (activation1): GELU(approximate='none')\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (pconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (activation2): GELU(approximate='none')\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): DepthWiseConvolutionBlock(\n",
       "      (dconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "      (activation1): GELU(approximate='none')\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (pconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (activation2): GELU(approximate='none')\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): DepthWiseConvolutionBlock(\n",
       "      (dconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "      (activation1): GELU(approximate='none')\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (pconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (activation2): GELU(approximate='none')\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): DepthWiseConvolutionBlock(\n",
       "      (dconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "      (activation1): GELU(approximate='none')\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (pconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (activation2): GELU(approximate='none')\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (gru): GRU(192, 256, batch_first=True, dropout=0.1)\n",
       "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and eval functions\n",
    "def train(model, dataloader, optimizer, loss_func, device):\n",
    "    model.train()\n",
    "    model = model.to(device)\n",
    "    total_loss, total_count, acc_count = 0, 0, 0\n",
    "\n",
    "    for idx, (X, y) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # print(X.shape)\n",
    "        # print(y.shape)\n",
    "\n",
    "        # Split X into input_tool and input_spec\n",
    "        input_spec = X[:, :in_channel_spec, ...]\n",
    "        input_tool = X[:, in_channel_spec:in_channel_spec + in_channel_tool, ...]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(input_spec, input_tool)\n",
    "        loss = loss_func(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Loss\n",
    "        total_loss += loss.item()\n",
    "        total_count += X.size(0) # Batch size\n",
    "\n",
    "        # Accuracy\n",
    "        _, y_pred_class = y_pred.max(dim=1)\n",
    "        acc_count += (y_pred_class == y).sum().item()\n",
    "\n",
    "    return total_loss/total_count, acc_count/total_count\n",
    "\n",
    "def evaluate(model, dataloader, loss_func, device):\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    total_loss, total_count, acc_count = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (X, y) in enumerate(dataloader):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # Split X into input_tool and input_spec\n",
    "            input_spec = X[:, :in_channel_spec, ...]\n",
    "            input_tool = X[:, in_channel_spec:in_channel_spec + in_channel_tool, ...]\n",
    "\n",
    "            y_pred = model(input_spec, input_tool)\n",
    "            loss = loss_func(y_pred, y)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_count += X.size(0)\n",
    "\n",
    "            # Accuracy\n",
    "            _, y_pred_class = y_pred.max(dim=1)\n",
    "            acc_count += (y_pred_class == y).sum().item()\n",
    "\n",
    "    return total_loss/total_count, acc_count/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started new epoch ..\n",
      "======================================================================================================\n",
      "| Epoch 1/10 | time: 243.660 | Train Loss: 0.003 | Val Loss: 0.004 | Train Acc: 0.942 | Val Acc: 0.889 |\n",
      "started new epoch ..\n",
      "======================================================================================================\n",
      "| Epoch 2/10 | time: 236.307 | Train Loss: 0.001 | Val Loss: 0.003 | Train Acc: 0.984 | Val Acc: 0.944 |\n",
      "started new epoch ..\n",
      "======================================================================================================\n",
      "| Epoch 3/10 | time: 242.579 | Train Loss: 0.000 | Val Loss: 0.003 | Train Acc: 0.992 | Val Acc: 0.963 |\n",
      "started new epoch ..\n",
      "======================================================================================================\n",
      "| Epoch 4/10 | time: 240.112 | Train Loss: 0.000 | Val Loss: 0.003 | Train Acc: 0.996 | Val Acc: 0.963 |\n",
      "started new epoch ..\n",
      "======================================================================================================\n",
      "| Epoch 5/10 | time: 235.187 | Train Loss: 0.000 | Val Loss: 0.003 | Train Acc: 0.999 | Val Acc: 0.963 |\n",
      "started new epoch ..\n",
      "======================================================================================================\n",
      "| Epoch 6/10 | time: 222.801 | Train Loss: 0.000 | Val Loss: 0.003 | Train Acc: 1.000 | Val Acc: 0.963 |\n",
      "started new epoch ..\n",
      "======================================================================================================\n",
      "| Epoch 7/10 | time: 224.230 | Train Loss: 0.000 | Val Loss: 0.003 | Train Acc: 1.000 | Val Acc: 0.963 |\n",
      "started new epoch ..\n",
      "======================================================================================================\n",
      "| Epoch 8/10 | time: 222.600 | Train Loss: 0.000 | Val Loss: 0.003 | Train Acc: 1.000 | Val Acc: 0.963 |\n",
      "started new epoch ..\n",
      "======================================================================================================\n",
      "| Epoch 9/10 | time: 221.380 | Train Loss: 0.000 | Val Loss: 0.003 | Train Acc: 1.000 | Val Acc: 0.963 |\n",
      "started new epoch ..\n",
      "======================================================================================================\n",
      "| Epoch 10/10 | time: 225.632 | Train Loss: 0.000 | Val Loss: 0.003 | Train Acc: 1.000 | Val Acc: 0.963 |\n"
     ]
    }
   ],
   "source": [
    "#training loop\n",
    "train_loss_epochs = []\n",
    "val_loss_epochs = []\n",
    "train_acc_epochs = []\n",
    "val_acc_epochs = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start = time.time()\n",
    "    print(\"started new epoch ..\")\n",
    "    loss_train, train_acc = train(model, train_dataloader, optimizer, loss_func, device)\n",
    "    loss_val, val_acc = evaluate(model, val_dataloader, loss_func, device)\n",
    "\n",
    "    train_loss_epochs.append(loss_train)\n",
    "    val_loss_epochs.append(loss_val)\n",
    "    train_acc_epochs.append(train_acc)\n",
    "    val_acc_epochs.append(val_acc)\n",
    "    end = time.time()\n",
    "\n",
    "    print(\"=\" * 102)\n",
    "    print(f\"| Epoch {epoch+1}/{num_epochs} | time: {(end-start):.3f} | Train Loss: {loss_train:.3f} | Val Loss: {loss_val:.3f} | Train Acc: {train_acc:.3f} | Val Acc: {val_acc:.3f} |\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.9791666666666666\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model, test_dataloader, loss_func, device)\n",
    "print(\"Test Accuracy: \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save loss and accuracy\n",
    "torch.save(model.state_dict(), \"models/rnn_model\")\n",
    "torch.save(train_loss_epochs, \"output/train_loss_epochs.pt\")\n",
    "torch.save(val_loss_epochs, \"output/val_loss_epochs.pt\")\n",
    "torch.save(train_acc_epochs, \"output/train_acc_epochs.pt\")\n",
    "torch.save(val_acc_epochs, \"output/val_acc_epochs.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot Epoch vs. Loss\n",
    "plt.plot(train_loss_epochs, label=\"Train\")\n",
    "plt.plot(val_loss_epochs, label=\"Validation\")\n",
    "plt.title(\"Epoch vs Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "#plot Epoch vs. Accuracy\n",
    "plt.plot(train_acc_epochs, label=\"Train\")\n",
    "plt.plot(val_acc_epochs, label=\"Validation\")\n",
    "plt.title(\"Epoch vs Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
